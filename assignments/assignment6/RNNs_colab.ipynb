{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNs_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shereshevskiy/dlcourse_ai/blob/master/assignments/assignment6/RNNs_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDo27Tj0fjpB",
        "colab_type": "text"
      },
      "source": [
        "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
        "\n",
        "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0ptCPrSg80R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "35770d56-832b-4f53-8faf-f8222997ea67"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssSpxAexiINJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15d0d9be-cfda-4229-ef02-fc6b07849cb1"
      },
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/Colab Notebooks/dlcourse_ai/dlcourse_ai/assignments/assignment6\")\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNNs_colab.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P59NYU98GCb9",
        "colab": {}
      },
      "source": [
        "!pip3 -qq install torch==0.4.1\n",
        "!pip3 -qq install bokeh==0.13.0\n",
        "!pip3 -qq install gensim==3.6.0\n",
        "!pip3 -qq install nltk\n",
        "!pip3 -qq install scikit-learn==0.20.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8sVtGHmA9aBM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TiA2dGmgF1rW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3d8e82c5-817f-4157-a760-ff5a057066f1"
      },
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QstS4NO0L97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "90c24980-ae36-4067-802f-fe16b17afead"
      },
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xTai8Ta0lgwL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7948d968-4958-4cdd-fd9c-34037d0a8ca1"
      },
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCjwwDs6Zq9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ccf5cb1-0df0-42d9-e9b6-ae98ec4b3629"
      },
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in train = 45441. Tags = {'VERB', 'NOUN', 'ADP', 'PRT', 'ADV', 'NUM', 'PRON', 'DET', 'CONJ', '.', 'X', 'ADJ'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URC1B2nvPGFt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "473d4858-8308-4691-f925-f924f090ebc3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAEyCAYAAABH+Yw/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5rWmSToIaeAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "221dc70a-ebd1-4878-e399-91a3493453ad"
      },
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07Ymb_MkbWsF"
      },
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjz_Rk0bbMyH",
        "colab": {}
      },
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uWMw6QHvbaDd"
      },
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XCuxEBVbOY_",
        "colab": {}
      },
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RtRbz1SwgEqc",
        "colab": {}
      },
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhsTKZalfih6",
        "colab": {}
      },
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l4XsRII5kW5x",
        "colab": {}
      },
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C5I9E9P6eFYv"
      },
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WVEHju54d68T",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        <create layers>\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        <apply them>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jbrxsZ2mehWB",
        "colab": {}
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "\n",
        "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
        "\n",
        "logits = model(X_batch)\n",
        "\n",
        "<calc accuracy>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GMUyUm1hgpe3",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "<calc loss>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSgV3NPUpcjH"
      },
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FprPQ0gllo7b",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "                logits = model(X_batch)\n",
        "\n",
        "                loss = <calc loss>\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                cur_correct_count, cur_sum_count = <calc accuracy>\n",
        "\n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count, correct_count / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None):\n",
        "        \n",
        "    if not val_data is None and val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_data is None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pqfbeh1ltEYa",
        "colab": {}
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0qGetIhfUE5"
      },
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAfV2dEOfHo5"
      },
      "source": [
        "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "98wr38_rw55D",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8COtGazgfjp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZTXmYGD_ANhm"
      },
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZpY_Q1xZ18h",
        "colab": {}
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsCstxiO03oT",
        "colab": {}
      },
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LxaRBpQd0pat",
        "colab": {}
      },
      "source": [
        "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        <create me>\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        <use me>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EBtI6BDE-Fc7",
        "colab": {}
      },
      "source": [
        "model = LSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Ne_8f24h8kg"
      },
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
        "\n",
        "Добейтесь качества лучше прошлых моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HPUuAPGhEGVR",
        "colab": {}
      },
      "source": [
        "<calc test accuracy>"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}