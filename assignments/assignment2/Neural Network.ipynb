{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(os.path.join(\"..\", \"data\"), max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.474991, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302183, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302180, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302186, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302185, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302181, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302182, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302184, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302184, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302186, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302185, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302183, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302182, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302185, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302184, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302182, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302183, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302184, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302184, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302183, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD())\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down and train and val accuracy go up for every epoch\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a84157f940>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEaNJREFUeJzt3X/sXXV9x/Hna61scygU6RQpAk6cqRkC3hV/TVnA0rJZnDMTItoJjuhGMke22IRFtLhEQY1xIYxuY/6IAwaOWTdIaRj74SaMb/lRKL9aG4QOpNUS0TWBdbz3x/1Ub77eb7+H76/bwvOR3HzPOZ/P5573Od9z7+t7zrm3TVUhSdLPjLoASdK+wUCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqRm/qgLeDYOPfTQOuqoo0ZdhiTtVzZs2PC9qlo4Wb/9KhCOOuooxsbGRl2GJO1XknynSz8vGUmSAANBktQYCJIkwECQJDUGgiQJ6BgISZYleSDJliSrhrSfn+TeJBuT3JTkyIG2lUk2t8fKgeUHJFmT5MEk9yf57ZnZJEnSVEz6sdMk84BLgbcD24DbkqytqnsHut0B9KpqV5IPAxcD70lyCHAh0AMK2NDGPgFcAGyvqlcn+RngkBndMknSs9LlewhLgC1VtRUgyVXA6cCPA6Gqbh7ofwtwVps+FVhfVTvb2PXAMuBK4GzgNW38M8D3prUle3PDKvju3bP29JI0q172K7D8U7O+mi6XjA4HHhmY39aWTeQc4Ia9jU1ycJu/KMntSa5J8tJhT5bk3CRjScZ27NjRoVxJ0lR0OUPIkGU1tGNyFv3LQ2+bZOx8YBHwH1V1fpLzgc8A7/upzlVrgDUAvV5v6HonNQfJKkn7uy5nCNuAIwbmFwGPju+U5BT69wVWVNVTk4z9PrALuK4tvwY44VlVLkmaUV0C4TbgmCRHJzkAOANYO9ghyfHA5fTDYPtA0zpgaZIFSRYAS4F1VVXAN4CTWr+TGbgnIUmae5NeMqqq3UnOo//mPg+4oqo2JVkNjFXVWuAS4EDgmiQAD1fViqrameQi+qECsHrPDWbgo8BXknwe2AF8YEa3TJL0rKT/x/r+odfrlf/aqSQ9O0k2VFVvsn5+U1mSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEdAyEJMuSPJBkS5JVQ9rPT3Jvko1Jbkpy5EDbyiSb22PlkLFrk9wzvc2QJE3XpIGQZB5wKbAcWAycmWTxuG53AL2qOha4Fri4jT0EuBA4EVgCXJhkwcBzvwv40QxshyRpmrqcISwBtlTV1qp6GrgKOH2wQ1XdXFW72uwtwKI2fSqwvqp2VtUTwHpgGUCSA4HzgU9OfzMkSdPVJRAOBx4ZmN/Wlk3kHOCGDmMvAj4L7EKSNHJdAiFDltXQjslZQA+4ZG9jkxwHvKqqrpt05cm5ScaSjO3YsaNDuZKkqegSCNuAIwbmFwGPju+U5BTgAmBFVT01ydg3Aq9P8hDwTeDVSf5l2Mqrak1V9aqqt3Dhwg7lSpKmoksg3AYck+ToJAcAZwBrBzskOR64nH4YbB9oWgcsTbKg3UxeCqyrqsuq6uVVdRTwFuDBqjpp+psjSZqq+ZN1qKrdSc6j/+Y+D7iiqjYlWQ2MVdVa+peIDgSuSQLwcFWtqKqdSS6iHyoAq6tq56xsiSRpWlI19HbAPqnX69XY2Nioy5Ck/UqSDVXVm6yf31SWJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAR0DIcmyJA8k2ZJk1ZD285Pcm2RjkpuSHDnQtjLJ5vZY2Za9MMk/Jbk/yaYkn5q5TZIkTcWkgZBkHnApsBxYDJyZZPG4bncAvao6FrgWuLiNPQS4EDgRWAJcmGRBG/OZqnoNcDzw5iTLZ2B7JElT1OUMYQmwpaq2VtXTwFXA6YMdqurmqtrVZm8BFrXpU4H1VbWzqp4A1gPLqmpXVd3cxj4N3D4wRpI0Al0C4XDgkYH5bW3ZRM4Bbug6NsnBwDuAmzrUIkmaJfM79MmQZTW0Y3IW0APe1mVskvnAlcAXqmrrBM95LnAuwCte8YoO5UqSpqLLGcI24IiB+UXAo+M7JTkFuABYUVVPdRy7BthcVZ+faOVVtaaqelXVW7hwYYdyJUlT0SUQbgOOSXJ0kgOAM4C1gx2SHA9cTj8Mtg80rQOWJlnQbiYvbctI8kngIOAj098MSdJ0TRoIVbUbOI/+G/l9wN9V1aYkq5OsaN0uAQ4ErklyZ5K1bexO4CL6oXIbsLqqdiZZRP9sYjFwexvzwZneOElSd6kaejtgn9Tr9WpsbGzUZUjSfiXJhqrqTdbPbypLkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktR0CoQky5I8kGRLklVD2s9Pcm+SjUluSnLkQNvKJJvbY+XA8tcnubs95xeSZGY2SZI0FZMGQpJ5wKXAcmAxcGaSxeO63QH0qupY4Frg4jb2EOBC4ERgCXBhkgVtzGXAucAx7bFs2lsjSZqyLmcIS4AtVbW1qp4GrgJOH+xQVTdX1a42ewuwqE2fCqyvqp1V9QSwHliW5DDgxVX1raoq4MvAO2dgeyRJU9QlEA4HHhmY39aWTeQc4IZJxh7epid9ziTnJhlLMrZjx44O5UqSpqJLIAy7tl9DOyZnAT3gkknGdn7OqlpTVb2q6i1cuLBDuZKkqegSCNuAIwbmFwGPju+U5BTgAmBFVT01ydht/OSy0oTPKUmaO10C4TbgmCRHJzkAOANYO9ghyfHA5fTDYPtA0zpgaZIF7WbyUmBdVT0G/DDJG9qni94PfH0GtkeSNEXzJ+tQVbuTnEf/zX0ecEVVbUqyGhirqrX0LxEdCFzTPj36cFWtqKqdSS6iHyoAq6tqZ5v+MPBF4Ofp33O4AUnSyKT/IZ/9Q6/Xq7GxsVGXIUn7lSQbqqo3WT+/qSxJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCOgZCkmVJHkiyJcmqIe1vTXJ7kt1J3j2u7dNJ7mmP9wwsP7mNuTPJN5O8avqbI0maqkkDIck84FJgObAYODPJ4nHdHgZ+F/jbcWN/AzgBOA44EfiTJC9uzZcB762q49q4P536ZkiSpqvLGcISYEtVba2qp4GrgNMHO1TVQ1W1EXhm3NjFwL9W1e6q+h/gLmDZnmHAnnA4CHh0itsgSZoBXQLhcOCRgfltbVkXdwHLk7wwyaHArwNHtLYPAtcn2Qa8D/hUx+eUJM2CLoGQIcuqy5NX1Y3A9cB/AlcC3wJ2t+Y/Ak6rqkXA3wCfG7ry5NwkY0nGduzY0WW1kqQp6BII2/jJX/UAi3gWl3eq6s+q6riqejv9cNmcZCHwuqq6tXW7GnjTBOPXVFWvqnoLFy7sulpJ0rPUJRBuA45JcnSSA4AzgLVdnjzJvCQvadPHAscCNwJPAAcleXXr+nbgvmdbvCRp5syfrENV7U5yHrAOmAdcUVWbkqwGxqpqbZJfBa4DFgDvSPKJqnot8ALg35MAPAmcVVW7AZL8HvC1JM/QD4izZ2H7JEkdparT7YB9Qq/Xq7GxsVGXIUn7lSQbqqo3WT+/qSxJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ180ddwFz4xDc2ce+jT466DEmaksUvfzEXvuO1s74ezxAkScDz5AxhLpJVkvZ3niFIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVKTqhp1DZ0l2QF8Z4rDDwW+N4PlzDTrmx7rmx7rm559vb4jq2rhZJ32q0CYjiRjVdUbdR0Tsb7psb7psb7p2dfr68pLRpIkwECQJDXPp0BYM+oCJmF902N902N907Ov19fJ8+YegiRp755PZwiSpL14zgVCkmVJHkiyJcmqIe0/m+Tq1n5rkqPmsLYjktyc5L4km5L84ZA+JyX5QZI72+Njc1VfW/9DSe5u6x4b0p4kX2j7b2OSE+awtl8e2C93JnkyyUfG9ZnT/ZfkiiTbk9wzsOyQJOuTbG4/F0wwdmXrsznJyjms75Ik97ff33VJDp5g7F6PhVms7+NJ/nvgd3jaBGP3+lqfxfquHqjtoSR3TjB21vffjKuq58wDmAd8G3glcABwF7B4XJ/fB/6iTZ8BXD2H9R0GnNCmXwQ8OKS+k4B/HOE+fAg4dC/tpwE3AAHeANw6wt/1d+l/vnpk+w94K3ACcM/AsouBVW16FfDpIeMOAba2nwva9II5qm8pML9Nf3pYfV2OhVms7+PAH3f4/e/1tT5b9Y1r/yzwsVHtv5l+PNfOEJYAW6pqa1U9DVwFnD6uz+nAl9r0tcDJSTIXxVXVY1V1e5v+IXAfcPhcrHsGnQ58ufpuAQ5OctgI6jgZ+HZVTfWLijOiqv4N2Dlu8eAx9iXgnUOGngqsr6qdVfUEsB5YNhf1VdWNVbW7zd4CLJrp9XY1wf7rostrfdr2Vl973/gd4MqZXu+oPNcC4XDgkYH5bfz0G+6P+7QXxQ+Al8xJdQPaparjgVuHNL8xyV1Jbkgy1///ZwE3JtmQ5Nwh7V328Vw4g4lfiKPcfwAvrarHoP9HAPCLQ/rsK/vxbPpnfMNMdizMpvPaJa0rJrjkti/sv18DHq+qzRO0j3L/TclzLRCG/aU//mNUXfrMqiQHAl8DPlJVT45rvp3+ZZDXAX8O/MNc1ga8uapOAJYDf5DkrePa94X9dwCwArhmSPOo919X+8J+vADYDXx1gi6THQuz5TLgl4DjgMfoX5YZb+T7DziTvZ8djGr/TdlzLRC2AUcMzC8CHp2oT5L5wEFM7ZR1SpK8gH4YfLWq/n58e1U9WVU/atPXAy9Icuhc1VdVj7af24Hr6J+aD+qyj2fbcuD2qnp8fMOo91/z+J7LaO3n9iF9Rrof203s3wTeW+2C93gdjoVZUVWPV9X/VdUzwF9OsN5R77/5wLuAqyfqM6r9Nx3PtUC4DTgmydHtr8gzgLXj+qwF9nyi493AP0/0gphp7ZrjXwP3VdXnJujzsj33NJIsof87+v4c1fcLSV60Z5r+zcd7xnVbC7y/fdroDcAP9lwemUMT/mU2yv03YPAYWwl8fUifdcDSJAvaJZGlbdmsS7IM+Ciwoqp2TdCny7EwW/UN3pP6rQnW2+W1PptOAe6vqm3DGke5/6Zl1He1Z/pB/1MwD9L/BMIFbdlq+gc/wM/Rv9SwBfgv4JVzWNtb6J/WbgTubI/TgA8BH2p9zgM20f/UxC3Am+awvle29d7Vatiz/wbrC3Bp2793A705/v2+kP4b/EEDy0a2/+gH02PA/9L/q/Uc+vekbgI2t5+HtL494K8Gxp7djsMtwAfmsL4t9K+/7zkG93zq7uXA9Xs7Fuaovq+0Y2sj/Tf5w8bX1+Z/6rU+F/W15V/cc8wN9J3z/TfTD7+pLEkCnnuXjCRJU2QgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQLg/wHOjSES2DJkCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def forward(self, x):\n",
    "        result = ... # промежуточные вычисления\n",
    "        self.x = x # сохраняем значения, которые нам\n",
    "                   # понадобятся при обратном проходе\n",
    "        return result\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        dx = ... # используем сохраненные значения, чтобы \n",
    "        dw = ... # вычислить градиент по x и по w\n",
    "        self.w.grad += dw # аккумулируем градиент dw\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.327447, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317055, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308875, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302413, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297282, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293190, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289918, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287288, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285169, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282059, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280917, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279984, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279217, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278584, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278058, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277622, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277257, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276951, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276693, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.327797, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317322, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309072, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302554, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297383, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293268, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289971, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287328, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285198, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283473, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282073, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280930, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279995, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279228, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278595, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278068, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277631, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277267, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276960, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276704, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.338513, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.320917, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.309354, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.302162, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.291612, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.279376, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.272259, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.249074, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.224796, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.160366, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.077119, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.023314, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.990641, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.882378, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.865913, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.850085, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.830226, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.838123, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.812237, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.816095, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.761647, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.769044, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.771029, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.753963, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.715191, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.720617, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.700544, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.720224, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.739972, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.722064, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.677093, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.659074, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.643295, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.650655, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.648200, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.605776, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.613467, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.603818, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.607823, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.557173, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.571724, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.563613, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.535058, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.553322, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.521862, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.551279, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.533226, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.514212, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.489937, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.510153, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.522101, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.464724, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.432964, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.423723, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.432805, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.411636, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.431253, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.424014, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.431763, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.393281, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.386942, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.392408, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.389754, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.371687, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.383909, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.382041, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.392579, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.378158, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.377792, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.390032, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.372182, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.372677, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.375066, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.363849, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.382682, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.397308, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.371160, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.382351, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.391005, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.385355, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.347869, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.356205, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.400631, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.365190, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.349667, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.357898, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.365172, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.370781, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.346892, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.352720, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.341590, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.339883, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.344367, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.359988, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.343300, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.337527, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.345549, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.353123, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.332500, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.333938, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.330066, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.325719, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.328516, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.320576, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.324892, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.310105, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.320430, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.308837, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.296569, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.298800, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.305147, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.292964, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.294184, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.283020, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.286336, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.311874, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.307945, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.278573, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.274128, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.299602, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.308194, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.284072, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.268346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.279644, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.261962, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.286428, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.256874, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.267382, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.266512, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.268048, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.267290, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.290552, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.297965, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.282717, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.277372, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.276435, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.265663, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.253758, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.259296, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.245549, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.263141, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.254392, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.265931, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.259925, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.262231, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.250383, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.259467, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.259928, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.245491, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.277881, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.318376, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.302280, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.275931, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.244771, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.205394, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.121494, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.943060, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.803730, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 1.895753, Train accuracy: 0.533333, val accuracy: 0.133333\n",
      "Loss: 1.780033, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Loss: 1.692183, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.633246, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.525975, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.377188, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.339075, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.268941, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.245105, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.221194, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.169602, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.096079, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 0.5*1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(momentum=0.3), learning_rate=4e-1, num_epochs=20, batch_size=100)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **40%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.333514, Train accuracy: 0.000000, val accuracy: 0.133333\n",
      "Loss: 2.333509, Train accuracy: 0.000000, val accuracy: 0.133333\n",
      "Loss: 2.333499, Train accuracy: 0.000000, val accuracy: 0.133333\n",
      "Loss: 2.333486, Train accuracy: 0.000000, val accuracy: 0.133333\n",
      "Loss: 2.333468, Train accuracy: 0.000000, val accuracy: 0.200000\n",
      "Loss: 2.333447, Train accuracy: 0.000000, val accuracy: 0.200000\n",
      "Loss: 2.333423, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: 2.333397, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: 2.333368, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: 2.333337, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: 2.333304, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: 2.333269, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: 2.333233, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: 2.333195, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.333156, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.333116, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.333075, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.333033, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332991, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332947, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332903, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332859, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332814, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332768, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332722, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332676, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332630, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332583, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332536, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332489, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332442, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332394, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332346, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332299, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332251, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332203, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332155, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332107, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332059, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.332011, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331963, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331915, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331867, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331819, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331771, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331723, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331675, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331627, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331580, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331532, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331484, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331436, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331389, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331341, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331293, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331246, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331198, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331151, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331104, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331056, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.331009, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330962, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330915, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330868, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330821, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330774, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330727, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330680, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330634, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330587, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330541, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330494, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330448, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330401, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330355, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330309, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330263, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330217, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330171, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330125, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330079, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.330033, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329987, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329942, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329896, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329851, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329805, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329760, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329714, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329669, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329624, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329579, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329534, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329489, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329444, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329399, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329354, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329310, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329265, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329221, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329176, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329132, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329087, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.329043, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328999, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328955, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328911, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328867, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328823, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328779, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328735, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328691, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328647, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328604, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328560, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328517, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328473, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328430, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328387, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328344, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328300, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328257, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328214, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328171, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328128, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328086, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328043, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.328000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327958, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327915, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327873, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327830, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327788, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327745, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327703, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327661, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327619, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327577, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327535, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327493, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327451, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327409, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327368, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327326, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327284, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327243, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327201, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327160, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327118, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327077, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.327036, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326995, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326953, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326912, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326871, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326830, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326789, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326749, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326708, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326667, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326626, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326586, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326545, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326505, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326464, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326424, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326384, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326344, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326303, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326263, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326223, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326183, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326143, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326103, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326064, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326024, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325984, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325945, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325905, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325865, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325826, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325787, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325747, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325708, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325669, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325630, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325590, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325551, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325512, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325473, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325434, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325396, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325357, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325318, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325279, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325241, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325202, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325164, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325125, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.325087, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "best validation accuracy achieved: 0.200000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rate = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "\n",
    "trainer = Trainer(model, dataset, MomentumSGD(momentum=0.2), num_epochs, batch_size, learning_rate, learning_rate_decay)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "best_val_accuracy = np.max(val_history)  # FIXME\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.333597, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333592, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333582, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333568, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333551, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333530, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333506, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333479, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333450, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333419, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333386, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: 2.333352, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: 2.333315, Train accuracy: 0.000000, val accuracy: 0.133333\n",
      "Loss: 2.333278, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: 2.333239, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: 2.333199, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: 2.333158, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: 2.333116, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: 2.333073, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: 2.333030, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Wall time: 302 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rate = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "\n",
    "trainer = Trainer(model, dataset, MomentumSGD(momentum=0.2), num_epochs, batch_size, learning_rate, learning_rate_decay)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "# print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302569, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.302570, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.302571, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.302574, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.302571, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.302575, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.302565, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.302571, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.302572, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.302572, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.302633, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302630, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302630, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302631, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302629, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302632, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302629, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302630, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302631, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302632, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302745, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.302743, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.302739, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.302735, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.302740, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.302743, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.302745, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.302745, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.302739, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.302745, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.302624, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302627, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302630, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302631, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302630, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302628, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302628, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302627, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302629, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302629, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302736, Train accuracy: 0.106000, val accuracy: 0.130000\n",
      "Loss: 2.302745, Train accuracy: 0.106000, val accuracy: 0.130000\n",
      "Loss: 2.302734, Train accuracy: 0.106000, val accuracy: 0.130000\n",
      "Loss: 2.302735, Train accuracy: 0.106000, val accuracy: 0.130000\n",
      "Loss: 2.302735, Train accuracy: 0.106000, val accuracy: 0.130000\n",
      "Loss: 2.302735, Train accuracy: 0.106000, val accuracy: 0.130000\n",
      "Loss: 2.302736, Train accuracy: 0.106000, val accuracy: 0.130000\n",
      "Loss: 2.302734, Train accuracy: 0.106000, val accuracy: 0.130000\n",
      "Loss: 2.302732, Train accuracy: 0.106000, val accuracy: 0.130000\n",
      "Loss: 2.302736, Train accuracy: 0.106000, val accuracy: 0.130000\n",
      "Loss: 2.302643, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302643, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302646, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302645, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302647, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302646, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302647, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302648, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302645, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302649, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302899, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302899, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302904, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302902, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302891, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302898, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302894, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302907, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302902, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302901, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302673, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302669, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302672, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302671, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302678, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302676, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302675, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302669, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302673, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302673, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302641, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302647, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302643, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302645, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302654, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302651, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302644, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302648, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302643, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302647, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302441, Train accuracy: 0.073000, val accuracy: 0.090000\n",
      "Loss: 2.302432, Train accuracy: 0.073000, val accuracy: 0.090000\n",
      "Loss: 2.302436, Train accuracy: 0.073000, val accuracy: 0.090000\n",
      "Loss: 2.302434, Train accuracy: 0.073000, val accuracy: 0.090000\n",
      "Loss: 2.302437, Train accuracy: 0.073000, val accuracy: 0.090000\n",
      "Loss: 2.302428, Train accuracy: 0.073000, val accuracy: 0.090000\n",
      "Loss: 2.302435, Train accuracy: 0.073000, val accuracy: 0.090000\n",
      "Loss: 2.302433, Train accuracy: 0.073000, val accuracy: 0.100000\n",
      "Loss: 2.302433, Train accuracy: 0.073000, val accuracy: 0.100000\n",
      "Loss: 2.302438, Train accuracy: 0.073000, val accuracy: 0.100000\n",
      "Loss: 2.302557, Train accuracy: 0.175000, val accuracy: 0.220000\n",
      "Loss: 2.302560, Train accuracy: 0.175000, val accuracy: 0.220000\n",
      "Loss: 2.302560, Train accuracy: 0.175000, val accuracy: 0.220000\n",
      "Loss: 2.302559, Train accuracy: 0.175000, val accuracy: 0.220000\n",
      "Loss: 2.302556, Train accuracy: 0.176000, val accuracy: 0.220000\n",
      "Loss: 2.302557, Train accuracy: 0.176000, val accuracy: 0.220000\n",
      "Loss: 2.302558, Train accuracy: 0.176000, val accuracy: 0.220000\n",
      "Loss: 2.302557, Train accuracy: 0.176000, val accuracy: 0.220000\n",
      "Loss: 2.302552, Train accuracy: 0.176000, val accuracy: 0.220000\n",
      "Loss: 2.302555, Train accuracy: 0.176000, val accuracy: 0.220000\n",
      "Loss: 2.302456, Train accuracy: 0.105000, val accuracy: 0.090000\n",
      "Loss: 2.302461, Train accuracy: 0.105000, val accuracy: 0.090000\n",
      "Loss: 2.302458, Train accuracy: 0.105000, val accuracy: 0.090000\n",
      "Loss: 2.302462, Train accuracy: 0.105000, val accuracy: 0.090000\n",
      "Loss: 2.302457, Train accuracy: 0.105000, val accuracy: 0.090000\n",
      "Loss: 2.302454, Train accuracy: 0.105000, val accuracy: 0.090000\n",
      "Loss: 2.302457, Train accuracy: 0.105000, val accuracy: 0.090000\n",
      "Loss: 2.302457, Train accuracy: 0.105000, val accuracy: 0.090000\n",
      "Loss: 2.302454, Train accuracy: 0.105000, val accuracy: 0.090000\n",
      "Loss: 2.302457, Train accuracy: 0.105000, val accuracy: 0.090000\n",
      "Loss: 2.302520, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302520, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302524, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302524, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302520, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302520, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302530, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302522, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302523, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302515, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302718, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302709, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302710, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302707, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302713, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302717, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302712, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302705, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302710, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302714, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302647, Train accuracy: 0.084000, val accuracy: 0.080000\n",
      "Loss: 2.302645, Train accuracy: 0.084000, val accuracy: 0.080000\n",
      "Loss: 2.302648, Train accuracy: 0.084000, val accuracy: 0.080000\n",
      "Loss: 2.302649, Train accuracy: 0.084000, val accuracy: 0.080000\n",
      "Loss: 2.302651, Train accuracy: 0.084000, val accuracy: 0.080000\n",
      "Loss: 2.302653, Train accuracy: 0.084000, val accuracy: 0.080000\n",
      "Loss: 2.302646, Train accuracy: 0.084000, val accuracy: 0.080000\n",
      "Loss: 2.302647, Train accuracy: 0.084000, val accuracy: 0.080000\n",
      "Loss: 2.302647, Train accuracy: 0.084000, val accuracy: 0.080000\n",
      "Loss: 2.302650, Train accuracy: 0.084000, val accuracy: 0.080000\n",
      "Loss: 2.302773, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302779, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302782, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302772, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302769, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302774, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302782, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302771, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302778, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302783, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302529, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302534, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302534, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302533, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302532, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302530, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302530, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302527, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302528, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302529, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302947, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302938, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302942, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302952, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302945, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302941, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302943, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302945, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302944, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302950, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302461, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302465, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302462, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302460, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302457, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302462, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302465, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302474, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302465, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302461, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302633, Train accuracy: 0.097000, val accuracy: 0.080000\n",
      "Loss: 2.302634, Train accuracy: 0.097000, val accuracy: 0.080000\n",
      "Loss: 2.302630, Train accuracy: 0.097000, val accuracy: 0.080000\n",
      "Loss: 2.302634, Train accuracy: 0.097000, val accuracy: 0.080000\n",
      "Loss: 2.302631, Train accuracy: 0.097000, val accuracy: 0.080000\n",
      "Loss: 2.302636, Train accuracy: 0.097000, val accuracy: 0.080000\n",
      "Loss: 2.302632, Train accuracy: 0.097000, val accuracy: 0.080000\n",
      "Loss: 2.302635, Train accuracy: 0.097000, val accuracy: 0.080000\n",
      "Loss: 2.302635, Train accuracy: 0.097000, val accuracy: 0.080000\n",
      "Loss: 2.302631, Train accuracy: 0.097000, val accuracy: 0.080000\n",
      "Loss: 2.302616, Train accuracy: 0.086000, val accuracy: 0.080000\n",
      "Loss: 2.302620, Train accuracy: 0.086000, val accuracy: 0.080000\n",
      "Loss: 2.302614, Train accuracy: 0.086000, val accuracy: 0.080000\n",
      "Loss: 2.302617, Train accuracy: 0.086000, val accuracy: 0.080000\n",
      "Loss: 2.302614, Train accuracy: 0.086000, val accuracy: 0.080000\n",
      "Loss: 2.302614, Train accuracy: 0.086000, val accuracy: 0.080000\n",
      "Loss: 2.302615, Train accuracy: 0.086000, val accuracy: 0.080000\n",
      "Loss: 2.302614, Train accuracy: 0.086000, val accuracy: 0.080000\n",
      "Loss: 2.302616, Train accuracy: 0.086000, val accuracy: 0.080000\n",
      "Loss: 2.302613, Train accuracy: 0.086000, val accuracy: 0.080000\n",
      "Loss: 2.302664, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302664, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302663, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302658, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302666, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302664, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302658, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302663, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302656, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302664, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302648, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302658, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302651, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302649, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302648, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302651, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302645, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302645, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302650, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302651, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302461, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302458, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302460, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302455, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302459, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302462, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302467, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302466, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302459, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302455, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302582, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302583, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302579, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302577, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302580, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302585, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302586, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302579, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302585, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302587, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302549, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302551, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302551, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302550, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302553, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302551, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302549, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302550, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302548, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302549, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302645, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302646, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302647, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302642, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302649, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302641, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302638, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302650, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302645, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302641, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302636, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302643, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302639, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302637, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302640, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302638, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302639, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302642, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302638, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302635, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302539, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302537, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302540, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302536, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302537, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302534, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302542, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302541, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302542, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302536, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302489, Train accuracy: 0.126000, val accuracy: 0.220000\n",
      "Loss: 2.302486, Train accuracy: 0.126000, val accuracy: 0.220000\n",
      "Loss: 2.302489, Train accuracy: 0.126000, val accuracy: 0.220000\n",
      "Loss: 2.302489, Train accuracy: 0.126000, val accuracy: 0.220000\n",
      "Loss: 2.302489, Train accuracy: 0.126000, val accuracy: 0.220000\n",
      "Loss: 2.302489, Train accuracy: 0.126000, val accuracy: 0.220000\n",
      "Loss: 2.302491, Train accuracy: 0.126000, val accuracy: 0.220000\n",
      "Loss: 2.302487, Train accuracy: 0.126000, val accuracy: 0.220000\n",
      "Loss: 2.302488, Train accuracy: 0.126000, val accuracy: 0.220000\n",
      "Loss: 2.302491, Train accuracy: 0.126000, val accuracy: 0.220000\n",
      "Loss: 2.302391, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302389, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302388, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302390, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302394, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302390, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302389, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302387, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302389, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302386, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302483, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302470, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302471, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302472, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302480, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302470, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302480, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302471, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302477, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302472, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302796, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302789, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302805, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302792, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302782, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302785, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302791, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302787, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302786, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302794, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302609, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302611, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302608, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302609, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302610, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302609, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302611, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302610, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302610, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302612, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302517, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302510, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302511, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302507, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302508, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302507, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302510, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302516, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302506, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302511, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302521, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302516, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302519, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302518, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302519, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302514, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302515, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302513, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302517, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302521, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303401, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303402, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303401, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303402, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303403, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303405, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303400, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303408, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303404, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303402, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303456, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303456, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303453, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303461, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303453, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303459, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303458, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303455, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303457, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303461, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303414, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303417, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303414, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303418, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303412, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303414, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303413, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303415, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303416, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303411, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303292, Train accuracy: 0.065000, val accuracy: 0.050000\n",
      "Loss: 2.303288, Train accuracy: 0.065000, val accuracy: 0.050000\n",
      "Loss: 2.303290, Train accuracy: 0.065000, val accuracy: 0.050000\n",
      "Loss: 2.303283, Train accuracy: 0.065000, val accuracy: 0.050000\n",
      "Loss: 2.303286, Train accuracy: 0.065000, val accuracy: 0.050000\n",
      "Loss: 2.303287, Train accuracy: 0.065000, val accuracy: 0.050000\n",
      "Loss: 2.303280, Train accuracy: 0.065000, val accuracy: 0.050000\n",
      "Loss: 2.303279, Train accuracy: 0.065000, val accuracy: 0.050000\n",
      "Loss: 2.303279, Train accuracy: 0.065000, val accuracy: 0.050000\n",
      "Loss: 2.303285, Train accuracy: 0.065000, val accuracy: 0.050000\n",
      "Loss: 2.303144, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303145, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303143, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303145, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303145, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303142, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303143, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303150, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303148, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303144, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303323, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303326, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303326, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303327, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303328, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303325, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303330, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303327, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303327, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303327, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.303296, Train accuracy: 0.112000, val accuracy: 0.190000\n",
      "Loss: 2.303299, Train accuracy: 0.113000, val accuracy: 0.190000\n",
      "Loss: 2.303297, Train accuracy: 0.112000, val accuracy: 0.190000\n",
      "Loss: 2.303297, Train accuracy: 0.111000, val accuracy: 0.190000\n",
      "Loss: 2.303296, Train accuracy: 0.110000, val accuracy: 0.190000\n",
      "Loss: 2.303296, Train accuracy: 0.110000, val accuracy: 0.190000\n",
      "Loss: 2.303298, Train accuracy: 0.110000, val accuracy: 0.190000\n",
      "Loss: 2.303297, Train accuracy: 0.110000, val accuracy: 0.190000\n",
      "Loss: 2.303297, Train accuracy: 0.110000, val accuracy: 0.190000\n",
      "Loss: 2.303298, Train accuracy: 0.111000, val accuracy: 0.190000\n",
      "Loss: 2.303484, Train accuracy: 0.091000, val accuracy: 0.050000\n",
      "Loss: 2.303481, Train accuracy: 0.091000, val accuracy: 0.050000\n",
      "Loss: 2.303482, Train accuracy: 0.091000, val accuracy: 0.050000\n",
      "Loss: 2.303485, Train accuracy: 0.091000, val accuracy: 0.050000\n",
      "Loss: 2.303487, Train accuracy: 0.091000, val accuracy: 0.050000\n",
      "Loss: 2.303488, Train accuracy: 0.091000, val accuracy: 0.050000\n",
      "Loss: 2.303481, Train accuracy: 0.091000, val accuracy: 0.050000\n",
      "Loss: 2.303492, Train accuracy: 0.091000, val accuracy: 0.050000\n",
      "Loss: 2.303488, Train accuracy: 0.091000, val accuracy: 0.050000\n",
      "Loss: 2.303485, Train accuracy: 0.091000, val accuracy: 0.050000\n",
      "Loss: 2.303215, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303217, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303217, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303215, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303212, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303215, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303213, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303213, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303216, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303208, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303168, Train accuracy: 0.141000, val accuracy: 0.130000\n",
      "Loss: 2.303166, Train accuracy: 0.141000, val accuracy: 0.130000\n",
      "Loss: 2.303164, Train accuracy: 0.141000, val accuracy: 0.130000\n",
      "Loss: 2.303164, Train accuracy: 0.141000, val accuracy: 0.130000\n",
      "Loss: 2.303158, Train accuracy: 0.141000, val accuracy: 0.130000\n",
      "Loss: 2.303161, Train accuracy: 0.141000, val accuracy: 0.130000\n",
      "Loss: 2.303159, Train accuracy: 0.141000, val accuracy: 0.130000\n",
      "Loss: 2.303165, Train accuracy: 0.141000, val accuracy: 0.130000\n",
      "Loss: 2.303162, Train accuracy: 0.141000, val accuracy: 0.130000\n",
      "Loss: 2.303161, Train accuracy: 0.141000, val accuracy: 0.130000\n",
      "Loss: 2.303170, Train accuracy: 0.146000, val accuracy: 0.130000\n",
      "Loss: 2.303172, Train accuracy: 0.146000, val accuracy: 0.130000\n",
      "Loss: 2.303167, Train accuracy: 0.146000, val accuracy: 0.130000\n",
      "Loss: 2.303178, Train accuracy: 0.146000, val accuracy: 0.130000\n",
      "Loss: 2.303169, Train accuracy: 0.146000, val accuracy: 0.130000\n",
      "Loss: 2.303176, Train accuracy: 0.146000, val accuracy: 0.130000\n",
      "Loss: 2.303178, Train accuracy: 0.146000, val accuracy: 0.130000\n",
      "Loss: 2.303173, Train accuracy: 0.146000, val accuracy: 0.130000\n",
      "Loss: 2.303170, Train accuracy: 0.146000, val accuracy: 0.130000\n",
      "Loss: 2.303168, Train accuracy: 0.146000, val accuracy: 0.130000\n",
      "Loss: 2.303266, Train accuracy: 0.092000, val accuracy: 0.130000\n",
      "Loss: 2.303271, Train accuracy: 0.092000, val accuracy: 0.130000\n",
      "Loss: 2.303271, Train accuracy: 0.092000, val accuracy: 0.130000\n",
      "Loss: 2.303271, Train accuracy: 0.092000, val accuracy: 0.130000\n",
      "Loss: 2.303273, Train accuracy: 0.092000, val accuracy: 0.130000\n",
      "Loss: 2.303273, Train accuracy: 0.092000, val accuracy: 0.130000\n",
      "Loss: 2.303270, Train accuracy: 0.092000, val accuracy: 0.130000\n",
      "Loss: 2.303265, Train accuracy: 0.092000, val accuracy: 0.130000\n",
      "Loss: 2.303271, Train accuracy: 0.092000, val accuracy: 0.130000\n",
      "Loss: 2.303267, Train accuracy: 0.092000, val accuracy: 0.130000\n",
      "Loss: 2.342109, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342109, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342104, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342111, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342105, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342106, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342107, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342110, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342104, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342107, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342213, Train accuracy: 0.136000, val accuracy: 0.130000\n",
      "Loss: 2.342216, Train accuracy: 0.136000, val accuracy: 0.130000\n",
      "Loss: 2.342219, Train accuracy: 0.136000, val accuracy: 0.130000\n",
      "Loss: 2.342211, Train accuracy: 0.136000, val accuracy: 0.130000\n",
      "Loss: 2.342209, Train accuracy: 0.136000, val accuracy: 0.130000\n",
      "Loss: 2.342211, Train accuracy: 0.136000, val accuracy: 0.130000\n",
      "Loss: 2.342217, Train accuracy: 0.136000, val accuracy: 0.130000\n",
      "Loss: 2.342209, Train accuracy: 0.136000, val accuracy: 0.130000\n",
      "Loss: 2.342209, Train accuracy: 0.136000, val accuracy: 0.130000\n",
      "Loss: 2.342215, Train accuracy: 0.136000, val accuracy: 0.130000\n",
      "Loss: 2.341962, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341960, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341962, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341962, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341966, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341962, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341962, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341965, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341964, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341962, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342162, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342166, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342165, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342167, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342160, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342168, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342164, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342168, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342163, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342170, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342068, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342073, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342079, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342076, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342077, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342085, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342067, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342076, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342071, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342078, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342191, Train accuracy: 0.104000, val accuracy: 0.070000\n",
      "Loss: 2.342189, Train accuracy: 0.104000, val accuracy: 0.070000\n",
      "Loss: 2.342187, Train accuracy: 0.104000, val accuracy: 0.070000\n",
      "Loss: 2.342181, Train accuracy: 0.104000, val accuracy: 0.070000\n",
      "Loss: 2.342197, Train accuracy: 0.104000, val accuracy: 0.070000\n",
      "Loss: 2.342189, Train accuracy: 0.104000, val accuracy: 0.070000\n",
      "Loss: 2.342193, Train accuracy: 0.104000, val accuracy: 0.070000\n",
      "Loss: 2.342183, Train accuracy: 0.104000, val accuracy: 0.070000\n",
      "Loss: 2.342180, Train accuracy: 0.104000, val accuracy: 0.070000\n",
      "Loss: 2.342190, Train accuracy: 0.104000, val accuracy: 0.070000\n",
      "Loss: 2.341883, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341885, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341875, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341884, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341880, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341885, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341885, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341883, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341879, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341887, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341982, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.341981, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.341983, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.341982, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.341984, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.341985, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.341982, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.341981, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.341983, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.341986, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342335, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342323, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342334, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342332, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342329, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342328, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342341, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342334, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342336, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.342329, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.341912, Train accuracy: 0.140000, val accuracy: 0.170000\n",
      "Loss: 2.341911, Train accuracy: 0.140000, val accuracy: 0.170000\n",
      "Loss: 2.341923, Train accuracy: 0.140000, val accuracy: 0.170000\n",
      "Loss: 2.341911, Train accuracy: 0.140000, val accuracy: 0.170000\n",
      "Loss: 2.341932, Train accuracy: 0.140000, val accuracy: 0.170000\n",
      "Loss: 2.341908, Train accuracy: 0.140000, val accuracy: 0.170000\n",
      "Loss: 2.341917, Train accuracy: 0.140000, val accuracy: 0.170000\n",
      "Loss: 2.341922, Train accuracy: 0.141000, val accuracy: 0.170000\n",
      "Loss: 2.341912, Train accuracy: 0.142000, val accuracy: 0.170000\n",
      "Loss: 2.341912, Train accuracy: 0.142000, val accuracy: 0.170000\n",
      "Loss: 2.341961, Train accuracy: 0.089000, val accuracy: 0.050000\n",
      "Loss: 2.341967, Train accuracy: 0.089000, val accuracy: 0.050000\n",
      "Loss: 2.341958, Train accuracy: 0.089000, val accuracy: 0.050000\n",
      "Loss: 2.341961, Train accuracy: 0.089000, val accuracy: 0.050000\n",
      "Loss: 2.341959, Train accuracy: 0.089000, val accuracy: 0.050000\n",
      "Loss: 2.341961, Train accuracy: 0.089000, val accuracy: 0.050000\n",
      "Loss: 2.341965, Train accuracy: 0.089000, val accuracy: 0.050000\n",
      "Loss: 2.341963, Train accuracy: 0.089000, val accuracy: 0.050000\n",
      "Loss: 2.341972, Train accuracy: 0.089000, val accuracy: 0.050000\n",
      "Loss: 2.341965, Train accuracy: 0.089000, val accuracy: 0.050000\n",
      "Loss: 2.342002, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342002, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341999, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342001, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342003, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342001, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342002, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342004, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342001, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342000, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302494, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302493, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302492, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302491, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302488, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302491, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302487, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302490, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302489, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302490, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302612, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302615, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302613, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302615, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302607, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302606, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302605, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302611, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302610, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302609, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302826, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302815, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302827, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302825, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302821, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302812, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302814, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302817, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302811, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302822, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302479, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302478, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302481, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302476, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302478, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302480, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302479, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302478, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302468, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302471, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302591, Train accuracy: 0.085000, val accuracy: 0.060000\n",
      "Loss: 2.302587, Train accuracy: 0.085000, val accuracy: 0.060000\n",
      "Loss: 2.302587, Train accuracy: 0.083000, val accuracy: 0.060000\n",
      "Loss: 2.302590, Train accuracy: 0.082000, val accuracy: 0.060000\n",
      "Loss: 2.302585, Train accuracy: 0.083000, val accuracy: 0.060000\n",
      "Loss: 2.302583, Train accuracy: 0.083000, val accuracy: 0.060000\n",
      "Loss: 2.302586, Train accuracy: 0.083000, val accuracy: 0.060000\n",
      "Loss: 2.302585, Train accuracy: 0.084000, val accuracy: 0.060000\n",
      "Loss: 2.302581, Train accuracy: 0.085000, val accuracy: 0.060000\n",
      "Loss: 2.302585, Train accuracy: 0.085000, val accuracy: 0.060000\n",
      "Loss: 2.302723, Train accuracy: 0.091000, val accuracy: 0.100000\n",
      "Loss: 2.302729, Train accuracy: 0.090000, val accuracy: 0.090000\n",
      "Loss: 2.302726, Train accuracy: 0.090000, val accuracy: 0.090000\n",
      "Loss: 2.302730, Train accuracy: 0.091000, val accuracy: 0.090000\n",
      "Loss: 2.302724, Train accuracy: 0.089000, val accuracy: 0.090000\n",
      "Loss: 2.302722, Train accuracy: 0.089000, val accuracy: 0.090000\n",
      "Loss: 2.302718, Train accuracy: 0.089000, val accuracy: 0.090000\n",
      "Loss: 2.302723, Train accuracy: 0.090000, val accuracy: 0.090000\n",
      "Loss: 2.302722, Train accuracy: 0.091000, val accuracy: 0.090000\n",
      "Loss: 2.302721, Train accuracy: 0.091000, val accuracy: 0.090000\n",
      "Loss: 2.302648, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302649, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302650, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302644, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302648, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302649, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302643, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302647, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302642, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302648, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302448, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302446, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302442, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302443, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302447, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302440, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302440, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302446, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302437, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302438, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302520, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302514, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302517, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302516, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302512, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302515, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302511, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302504, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302510, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302511, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302392, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302389, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302396, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302397, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302395, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302393, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302389, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302383, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302392, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302383, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302705, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302704, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302710, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302707, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302705, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302701, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302698, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302698, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302697, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302698, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302549, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.302552, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.302553, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.302549, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.302545, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.302553, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.302546, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.302543, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.302537, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.302547, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302485, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302482, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302474, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302482, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302479, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302478, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302488, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302483, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302481, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302478, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302720, Train accuracy: 0.066000, val accuracy: 0.030000\n",
      "Loss: 2.302723, Train accuracy: 0.066000, val accuracy: 0.030000\n",
      "Loss: 2.302716, Train accuracy: 0.066000, val accuracy: 0.030000\n",
      "Loss: 2.302722, Train accuracy: 0.066000, val accuracy: 0.030000\n",
      "Loss: 2.302721, Train accuracy: 0.066000, val accuracy: 0.030000\n",
      "Loss: 2.302719, Train accuracy: 0.066000, val accuracy: 0.030000\n",
      "Loss: 2.302714, Train accuracy: 0.066000, val accuracy: 0.030000\n",
      "Loss: 2.302719, Train accuracy: 0.066000, val accuracy: 0.030000\n",
      "Loss: 2.302717, Train accuracy: 0.066000, val accuracy: 0.030000\n",
      "Loss: 2.302720, Train accuracy: 0.066000, val accuracy: 0.030000\n",
      "Loss: 2.302834, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302831, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302833, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302829, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302832, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302837, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302832, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302833, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302828, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302834, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302594, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302592, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302593, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302591, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302589, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302589, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302588, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302591, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302592, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302590, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302670, Train accuracy: 0.088000, val accuracy: 0.070000\n",
      "Loss: 2.302672, Train accuracy: 0.089000, val accuracy: 0.070000\n",
      "Loss: 2.302674, Train accuracy: 0.089000, val accuracy: 0.070000\n",
      "Loss: 2.302672, Train accuracy: 0.089000, val accuracy: 0.070000\n",
      "Loss: 2.302675, Train accuracy: 0.089000, val accuracy: 0.070000\n",
      "Loss: 2.302672, Train accuracy: 0.089000, val accuracy: 0.070000\n",
      "Loss: 2.302668, Train accuracy: 0.089000, val accuracy: 0.070000\n",
      "Loss: 2.302667, Train accuracy: 0.089000, val accuracy: 0.070000\n",
      "Loss: 2.302668, Train accuracy: 0.088000, val accuracy: 0.070000\n",
      "Loss: 2.302672, Train accuracy: 0.088000, val accuracy: 0.070000\n",
      "Loss: 2.302603, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302600, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302598, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302602, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302602, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302597, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302595, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302593, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302597, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302599, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302719, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302714, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302721, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302720, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302718, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302717, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302711, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302712, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302716, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302711, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302255, Train accuracy: 0.170000, val accuracy: 0.230000\n",
      "Loss: 2.302250, Train accuracy: 0.170000, val accuracy: 0.230000\n",
      "Loss: 2.302248, Train accuracy: 0.170000, val accuracy: 0.230000\n",
      "Loss: 2.302246, Train accuracy: 0.171000, val accuracy: 0.230000\n",
      "Loss: 2.302248, Train accuracy: 0.172000, val accuracy: 0.230000\n",
      "Loss: 2.302243, Train accuracy: 0.173000, val accuracy: 0.230000\n",
      "Loss: 2.302239, Train accuracy: 0.174000, val accuracy: 0.230000\n",
      "Loss: 2.302241, Train accuracy: 0.174000, val accuracy: 0.230000\n",
      "Loss: 2.302244, Train accuracy: 0.175000, val accuracy: 0.230000\n",
      "Loss: 2.302240, Train accuracy: 0.175000, val accuracy: 0.230000\n",
      "Loss: 2.302771, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302759, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302757, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302761, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302758, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302762, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302761, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302754, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302751, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302749, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302591, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302587, Train accuracy: 0.060000, val accuracy: 0.030000\n",
      "Loss: 2.302597, Train accuracy: 0.061000, val accuracy: 0.030000\n",
      "Loss: 2.302589, Train accuracy: 0.063000, val accuracy: 0.030000\n",
      "Loss: 2.302585, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302588, Train accuracy: 0.062000, val accuracy: 0.040000\n",
      "Loss: 2.302586, Train accuracy: 0.062000, val accuracy: 0.040000\n",
      "Loss: 2.302588, Train accuracy: 0.064000, val accuracy: 0.040000\n",
      "Loss: 2.302590, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302585, Train accuracy: 0.064000, val accuracy: 0.040000\n",
      "Loss: 2.302553, Train accuracy: 0.092000, val accuracy: 0.150000\n",
      "Loss: 2.302547, Train accuracy: 0.093000, val accuracy: 0.160000\n",
      "Loss: 2.302552, Train accuracy: 0.094000, val accuracy: 0.160000\n",
      "Loss: 2.302549, Train accuracy: 0.094000, val accuracy: 0.160000\n",
      "Loss: 2.302551, Train accuracy: 0.093000, val accuracy: 0.150000\n",
      "Loss: 2.302547, Train accuracy: 0.093000, val accuracy: 0.150000\n",
      "Loss: 2.302546, Train accuracy: 0.095000, val accuracy: 0.150000\n",
      "Loss: 2.302545, Train accuracy: 0.096000, val accuracy: 0.150000\n",
      "Loss: 2.302546, Train accuracy: 0.096000, val accuracy: 0.160000\n",
      "Loss: 2.302544, Train accuracy: 0.098000, val accuracy: 0.160000\n",
      "Loss: 2.302416, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302417, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302421, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302418, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302414, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302410, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302415, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302405, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302413, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302407, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302298, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302301, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302300, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302290, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302296, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302289, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302298, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302302, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302295, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302291, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302524, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302526, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302516, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302518, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302523, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302514, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302515, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302520, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302516, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302513, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302748, Train accuracy: 0.102000, val accuracy: 0.110000\n",
      "Loss: 2.302746, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.302744, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.302745, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.302755, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.302743, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.302752, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.302745, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.302741, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.302753, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.302531, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302534, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302538, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302531, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302534, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302530, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302529, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302533, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302528, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302531, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302615, Train accuracy: 0.068000, val accuracy: 0.070000\n",
      "Loss: 2.302613, Train accuracy: 0.071000, val accuracy: 0.070000\n",
      "Loss: 2.302619, Train accuracy: 0.072000, val accuracy: 0.070000\n",
      "Loss: 2.302620, Train accuracy: 0.072000, val accuracy: 0.070000\n",
      "Loss: 2.302617, Train accuracy: 0.072000, val accuracy: 0.070000\n",
      "Loss: 2.302614, Train accuracy: 0.073000, val accuracy: 0.070000\n",
      "Loss: 2.302617, Train accuracy: 0.073000, val accuracy: 0.070000\n",
      "Loss: 2.302611, Train accuracy: 0.072000, val accuracy: 0.070000\n",
      "Loss: 2.302615, Train accuracy: 0.073000, val accuracy: 0.070000\n",
      "Loss: 2.302613, Train accuracy: 0.073000, val accuracy: 0.070000\n",
      "Loss: 2.302571, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302562, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302566, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302567, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302565, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302566, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302564, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302567, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302567, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302565, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302639, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302636, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302634, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302633, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302635, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302630, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302627, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302628, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302627, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302624, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302734, Train accuracy: 0.105000, val accuracy: 0.190000\n",
      "Loss: 2.302730, Train accuracy: 0.105000, val accuracy: 0.190000\n",
      "Loss: 2.302736, Train accuracy: 0.105000, val accuracy: 0.190000\n",
      "Loss: 2.302726, Train accuracy: 0.105000, val accuracy: 0.190000\n",
      "Loss: 2.302742, Train accuracy: 0.105000, val accuracy: 0.190000\n",
      "Loss: 2.302736, Train accuracy: 0.105000, val accuracy: 0.190000\n",
      "Loss: 2.302734, Train accuracy: 0.104000, val accuracy: 0.190000\n",
      "Loss: 2.302728, Train accuracy: 0.105000, val accuracy: 0.190000\n",
      "Loss: 2.302732, Train accuracy: 0.105000, val accuracy: 0.190000\n",
      "Loss: 2.302732, Train accuracy: 0.104000, val accuracy: 0.190000\n",
      "Loss: 2.302662, Train accuracy: 0.090000, val accuracy: 0.080000\n",
      "Loss: 2.302662, Train accuracy: 0.090000, val accuracy: 0.080000\n",
      "Loss: 2.302657, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302660, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302662, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302657, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302656, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302657, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302656, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302652, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302633, Train accuracy: 0.065000, val accuracy: 0.020000\n",
      "Loss: 2.302627, Train accuracy: 0.066000, val accuracy: 0.020000\n",
      "Loss: 2.302629, Train accuracy: 0.066000, val accuracy: 0.020000\n",
      "Loss: 2.302632, Train accuracy: 0.067000, val accuracy: 0.020000\n",
      "Loss: 2.302625, Train accuracy: 0.067000, val accuracy: 0.020000\n",
      "Loss: 2.302625, Train accuracy: 0.068000, val accuracy: 0.020000\n",
      "Loss: 2.302621, Train accuracy: 0.069000, val accuracy: 0.020000\n",
      "Loss: 2.302628, Train accuracy: 0.070000, val accuracy: 0.020000\n",
      "Loss: 2.302621, Train accuracy: 0.071000, val accuracy: 0.020000\n",
      "Loss: 2.302621, Train accuracy: 0.071000, val accuracy: 0.020000\n",
      "Loss: 2.302619, Train accuracy: 0.176000, val accuracy: 0.220000\n",
      "Loss: 2.302620, Train accuracy: 0.177000, val accuracy: 0.220000\n",
      "Loss: 2.302618, Train accuracy: 0.178000, val accuracy: 0.220000\n",
      "Loss: 2.302615, Train accuracy: 0.180000, val accuracy: 0.220000\n",
      "Loss: 2.302619, Train accuracy: 0.181000, val accuracy: 0.220000\n",
      "Loss: 2.302615, Train accuracy: 0.180000, val accuracy: 0.220000\n",
      "Loss: 2.302613, Train accuracy: 0.180000, val accuracy: 0.220000\n",
      "Loss: 2.302610, Train accuracy: 0.182000, val accuracy: 0.220000\n",
      "Loss: 2.302616, Train accuracy: 0.182000, val accuracy: 0.220000\n",
      "Loss: 2.302615, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.302665, Train accuracy: 0.089000, val accuracy: 0.060000\n",
      "Loss: 2.302660, Train accuracy: 0.091000, val accuracy: 0.070000\n",
      "Loss: 2.302656, Train accuracy: 0.091000, val accuracy: 0.080000\n",
      "Loss: 2.302661, Train accuracy: 0.091000, val accuracy: 0.080000\n",
      "Loss: 2.302663, Train accuracy: 0.092000, val accuracy: 0.080000\n",
      "Loss: 2.302653, Train accuracy: 0.094000, val accuracy: 0.080000\n",
      "Loss: 2.302656, Train accuracy: 0.095000, val accuracy: 0.080000\n",
      "Loss: 2.302649, Train accuracy: 0.092000, val accuracy: 0.080000\n",
      "Loss: 2.302657, Train accuracy: 0.095000, val accuracy: 0.080000\n",
      "Loss: 2.302659, Train accuracy: 0.094000, val accuracy: 0.080000\n",
      "Loss: 2.303602, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303601, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303586, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303594, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303590, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303601, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303588, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303581, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303589, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303586, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.303598, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303599, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303590, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303599, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303590, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303599, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303598, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303599, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303593, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303593, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303167, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303171, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303164, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303167, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303165, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303165, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303165, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303168, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303160, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303166, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303321, Train accuracy: 0.075000, val accuracy: 0.030000\n",
      "Loss: 2.303322, Train accuracy: 0.075000, val accuracy: 0.030000\n",
      "Loss: 2.303322, Train accuracy: 0.075000, val accuracy: 0.030000\n",
      "Loss: 2.303320, Train accuracy: 0.074000, val accuracy: 0.030000\n",
      "Loss: 2.303321, Train accuracy: 0.075000, val accuracy: 0.030000\n",
      "Loss: 2.303317, Train accuracy: 0.075000, val accuracy: 0.030000\n",
      "Loss: 2.303316, Train accuracy: 0.075000, val accuracy: 0.030000\n",
      "Loss: 2.303321, Train accuracy: 0.075000, val accuracy: 0.030000\n",
      "Loss: 2.303319, Train accuracy: 0.075000, val accuracy: 0.030000\n",
      "Loss: 2.303320, Train accuracy: 0.075000, val accuracy: 0.030000\n",
      "Loss: 2.303345, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303345, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303351, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303354, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303340, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303350, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303342, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303350, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303345, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303353, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.303210, Train accuracy: 0.084000, val accuracy: 0.070000\n",
      "Loss: 2.303206, Train accuracy: 0.086000, val accuracy: 0.070000\n",
      "Loss: 2.303209, Train accuracy: 0.086000, val accuracy: 0.070000\n",
      "Loss: 2.303210, Train accuracy: 0.086000, val accuracy: 0.070000\n",
      "Loss: 2.303213, Train accuracy: 0.086000, val accuracy: 0.070000\n",
      "Loss: 2.303209, Train accuracy: 0.088000, val accuracy: 0.070000\n",
      "Loss: 2.303210, Train accuracy: 0.088000, val accuracy: 0.070000\n",
      "Loss: 2.303204, Train accuracy: 0.088000, val accuracy: 0.070000\n",
      "Loss: 2.303208, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303208, Train accuracy: 0.091000, val accuracy: 0.070000\n",
      "Loss: 2.303353, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303342, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303352, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303346, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303344, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303331, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303343, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303340, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303343, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303342, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.303286, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303273, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303284, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303277, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303279, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303282, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303279, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303271, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303281, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303269, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303369, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303371, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303377, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303374, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303367, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303366, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303367, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303365, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303359, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303361, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303219, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303208, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303208, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303207, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303215, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303205, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303205, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303206, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303205, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303200, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303248, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303250, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303243, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303246, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303245, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303241, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303242, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303233, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303235, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303237, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.303298, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.303295, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.303296, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.303293, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.303293, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.303291, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.303291, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.303286, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.303285, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.303287, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.341936, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.341933, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.341924, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.341932, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.341928, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.341931, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.341929, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.341923, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.341924, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.341924, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.342265, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.342275, Train accuracy: 0.109000, val accuracy: 0.070000\n",
      "Loss: 2.342275, Train accuracy: 0.109000, val accuracy: 0.070000\n",
      "Loss: 2.342273, Train accuracy: 0.109000, val accuracy: 0.070000\n",
      "Loss: 2.342259, Train accuracy: 0.109000, val accuracy: 0.070000\n",
      "Loss: 2.342268, Train accuracy: 0.109000, val accuracy: 0.070000\n",
      "Loss: 2.342265, Train accuracy: 0.110000, val accuracy: 0.070000\n",
      "Loss: 2.342264, Train accuracy: 0.110000, val accuracy: 0.070000\n",
      "Loss: 2.342259, Train accuracy: 0.110000, val accuracy: 0.070000\n",
      "Loss: 2.342276, Train accuracy: 0.110000, val accuracy: 0.070000\n",
      "Loss: 2.341999, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341998, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341999, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341994, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341996, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341993, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341992, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341995, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341993, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341991, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341998, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341994, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341990, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341990, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341989, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341983, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341987, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341985, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341989, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341979, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341684, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341687, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341683, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341679, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341680, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341680, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341680, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341681, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341675, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341677, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.342076, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342073, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342069, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342069, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342066, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342058, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342063, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342064, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342064, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342060, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342211, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342212, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342210, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342206, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342203, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342202, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342198, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342197, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342196, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342195, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.342087, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342080, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342077, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342079, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342070, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342073, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342071, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342069, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342067, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342063, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341975, Train accuracy: 0.102000, val accuracy: 0.100000\n",
      "Loss: 2.341966, Train accuracy: 0.102000, val accuracy: 0.110000\n",
      "Loss: 2.341975, Train accuracy: 0.102000, val accuracy: 0.110000\n",
      "Loss: 2.341969, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.341960, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.341964, Train accuracy: 0.103000, val accuracy: 0.110000\n",
      "Loss: 2.341959, Train accuracy: 0.104000, val accuracy: 0.100000\n",
      "Loss: 2.341960, Train accuracy: 0.105000, val accuracy: 0.100000\n",
      "Loss: 2.341951, Train accuracy: 0.105000, val accuracy: 0.100000\n",
      "Loss: 2.341955, Train accuracy: 0.105000, val accuracy: 0.100000\n",
      "Loss: 2.342187, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342186, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342187, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342175, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342175, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342177, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342174, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342172, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342164, Train accuracy: 0.064000, val accuracy: 0.040000\n",
      "Loss: 2.342165, Train accuracy: 0.064000, val accuracy: 0.040000\n",
      "Loss: 2.341736, Train accuracy: 0.069000, val accuracy: 0.030000\n",
      "Loss: 2.341727, Train accuracy: 0.071000, val accuracy: 0.030000\n",
      "Loss: 2.341740, Train accuracy: 0.067000, val accuracy: 0.040000\n",
      "Loss: 2.341726, Train accuracy: 0.066000, val accuracy: 0.040000\n",
      "Loss: 2.341724, Train accuracy: 0.071000, val accuracy: 0.040000\n",
      "Loss: 2.341717, Train accuracy: 0.076000, val accuracy: 0.050000\n",
      "Loss: 2.341717, Train accuracy: 0.079000, val accuracy: 0.040000\n",
      "Loss: 2.341715, Train accuracy: 0.079000, val accuracy: 0.040000\n",
      "Loss: 2.341717, Train accuracy: 0.079000, val accuracy: 0.040000\n",
      "Loss: 2.341713, Train accuracy: 0.080000, val accuracy: 0.040000\n",
      "Loss: 2.341887, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341890, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341883, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341882, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341879, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341876, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341874, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341869, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341867, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341868, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302406, Train accuracy: 0.177000, val accuracy: 0.210000\n",
      "Loss: 2.302350, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302294, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302275, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302234, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302213, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302203, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302182, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302173, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302180, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302571, Train accuracy: 0.097000, val accuracy: 0.120000\n",
      "Loss: 2.302514, Train accuracy: 0.101000, val accuracy: 0.110000\n",
      "Loss: 2.302462, Train accuracy: 0.102000, val accuracy: 0.090000\n",
      "Loss: 2.302427, Train accuracy: 0.101000, val accuracy: 0.080000\n",
      "Loss: 2.302399, Train accuracy: 0.102000, val accuracy: 0.080000\n",
      "Loss: 2.302380, Train accuracy: 0.104000, val accuracy: 0.080000\n",
      "Loss: 2.302365, Train accuracy: 0.106000, val accuracy: 0.080000\n",
      "Loss: 2.302355, Train accuracy: 0.107000, val accuracy: 0.080000\n",
      "Loss: 2.302351, Train accuracy: 0.107000, val accuracy: 0.080000\n",
      "Loss: 2.302342, Train accuracy: 0.106000, val accuracy: 0.080000\n",
      "Loss: 2.302677, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302618, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302565, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302526, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302494, Train accuracy: 0.059000, val accuracy: 0.030000\n",
      "Loss: 2.302484, Train accuracy: 0.068000, val accuracy: 0.030000\n",
      "Loss: 2.302469, Train accuracy: 0.096000, val accuracy: 0.070000\n",
      "Loss: 2.302454, Train accuracy: 0.130000, val accuracy: 0.130000\n",
      "Loss: 2.302452, Train accuracy: 0.144000, val accuracy: 0.180000\n",
      "Loss: 2.302446, Train accuracy: 0.150000, val accuracy: 0.160000\n",
      "Loss: 2.302515, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302463, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302398, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302352, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302325, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302289, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302261, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302243, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302228, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302211, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302649, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302594, Train accuracy: 0.056000, val accuracy: 0.040000\n",
      "Loss: 2.302543, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302486, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302443, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302412, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302395, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302368, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302357, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302333, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302672, Train accuracy: 0.089000, val accuracy: 0.070000\n",
      "Loss: 2.302611, Train accuracy: 0.089000, val accuracy: 0.070000\n",
      "Loss: 2.302554, Train accuracy: 0.089000, val accuracy: 0.060000\n",
      "Loss: 2.302506, Train accuracy: 0.090000, val accuracy: 0.050000\n",
      "Loss: 2.302467, Train accuracy: 0.100000, val accuracy: 0.060000\n",
      "Loss: 2.302436, Train accuracy: 0.096000, val accuracy: 0.050000\n",
      "Loss: 2.302409, Train accuracy: 0.102000, val accuracy: 0.070000\n",
      "Loss: 2.302389, Train accuracy: 0.108000, val accuracy: 0.070000\n",
      "Loss: 2.302377, Train accuracy: 0.109000, val accuracy: 0.080000\n",
      "Loss: 2.302367, Train accuracy: 0.114000, val accuracy: 0.090000\n",
      "Loss: 2.302490, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302432, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302366, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302295, Train accuracy: 0.112000, val accuracy: 0.190000\n",
      "Loss: 2.302244, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302183, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302111, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302073, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302006, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301956, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302790, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302737, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302671, Train accuracy: 0.062000, val accuracy: 0.080000\n",
      "Loss: 2.302598, Train accuracy: 0.082000, val accuracy: 0.080000\n",
      "Loss: 2.302528, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302473, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302420, Train accuracy: 0.130000, val accuracy: 0.110000\n",
      "Loss: 2.302367, Train accuracy: 0.182000, val accuracy: 0.200000\n",
      "Loss: 2.302303, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302259, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302465, Train accuracy: 0.169000, val accuracy: 0.220000\n",
      "Loss: 2.302403, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302336, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302278, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302213, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302151, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302084, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302041, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301993, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301926, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302693, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302632, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302553, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302496, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302409, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302350, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302285, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302215, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.302138, Train accuracy: 0.103000, val accuracy: 0.090000\n",
      "Loss: 2.302052, Train accuracy: 0.114000, val accuracy: 0.100000\n",
      "Loss: 2.302401, Train accuracy: 0.110000, val accuracy: 0.200000\n",
      "Loss: 2.302348, Train accuracy: 0.165000, val accuracy: 0.210000\n",
      "Loss: 2.302272, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302198, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302133, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302053, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301985, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301914, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301854, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301787, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302529, Train accuracy: 0.111000, val accuracy: 0.210000\n",
      "Loss: 2.302468, Train accuracy: 0.152000, val accuracy: 0.140000\n",
      "Loss: 2.302400, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302330, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302261, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302184, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302115, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302042, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301980, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301902, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302617, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302570, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302514, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302479, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.302456, Train accuracy: 0.057000, val accuracy: 0.030000\n",
      "Loss: 2.302434, Train accuracy: 0.058000, val accuracy: 0.030000\n",
      "Loss: 2.302420, Train accuracy: 0.066000, val accuracy: 0.070000\n",
      "Loss: 2.302406, Train accuracy: 0.083000, val accuracy: 0.120000\n",
      "Loss: 2.302400, Train accuracy: 0.113000, val accuracy: 0.150000\n",
      "Loss: 2.302394, Train accuracy: 0.137000, val accuracy: 0.170000\n",
      "Loss: 2.302598, Train accuracy: 0.066000, val accuracy: 0.060000\n",
      "Loss: 2.302544, Train accuracy: 0.089000, val accuracy: 0.140000\n",
      "Loss: 2.302502, Train accuracy: 0.104000, val accuracy: 0.180000\n",
      "Loss: 2.302455, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302430, Train accuracy: 0.112000, val accuracy: 0.200000\n",
      "Loss: 2.302416, Train accuracy: 0.123000, val accuracy: 0.250000\n",
      "Loss: 2.302393, Train accuracy: 0.146000, val accuracy: 0.230000\n",
      "Loss: 2.302394, Train accuracy: 0.166000, val accuracy: 0.260000\n",
      "Loss: 2.302379, Train accuracy: 0.167000, val accuracy: 0.240000\n",
      "Loss: 2.302373, Train accuracy: 0.173000, val accuracy: 0.250000\n",
      "Loss: 2.302709, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302652, Train accuracy: 0.091000, val accuracy: 0.070000\n",
      "Loss: 2.302592, Train accuracy: 0.093000, val accuracy: 0.090000\n",
      "Loss: 2.302560, Train accuracy: 0.094000, val accuracy: 0.090000\n",
      "Loss: 2.302536, Train accuracy: 0.142000, val accuracy: 0.100000\n",
      "Loss: 2.302503, Train accuracy: 0.163000, val accuracy: 0.150000\n",
      "Loss: 2.302491, Train accuracy: 0.174000, val accuracy: 0.210000\n",
      "Loss: 2.302490, Train accuracy: 0.179000, val accuracy: 0.230000\n",
      "Loss: 2.302489, Train accuracy: 0.180000, val accuracy: 0.230000\n",
      "Loss: 2.302473, Train accuracy: 0.181000, val accuracy: 0.240000\n",
      "Loss: 2.302418, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302359, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302295, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302250, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302207, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302177, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302167, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302138, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302125, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302108, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302624, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302568, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302511, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302461, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302428, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302395, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302367, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302345, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302333, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302309, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302602, Train accuracy: 0.113000, val accuracy: 0.170000\n",
      "Loss: 2.302553, Train accuracy: 0.110000, val accuracy: 0.210000\n",
      "Loss: 2.302494, Train accuracy: 0.110000, val accuracy: 0.200000\n",
      "Loss: 2.302441, Train accuracy: 0.110000, val accuracy: 0.200000\n",
      "Loss: 2.302400, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302377, Train accuracy: 0.107000, val accuracy: 0.200000\n",
      "Loss: 2.302347, Train accuracy: 0.106000, val accuracy: 0.200000\n",
      "Loss: 2.302322, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302311, Train accuracy: 0.109000, val accuracy: 0.200000\n",
      "Loss: 2.302299, Train accuracy: 0.116000, val accuracy: 0.210000\n",
      "Loss: 2.302730, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302679, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302608, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302537, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302472, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.302418, Train accuracy: 0.085000, val accuracy: 0.070000\n",
      "Loss: 2.302354, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302297, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302248, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302201, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302523, Train accuracy: 0.126000, val accuracy: 0.120000\n",
      "Loss: 2.302464, Train accuracy: 0.143000, val accuracy: 0.130000\n",
      "Loss: 2.302401, Train accuracy: 0.156000, val accuracy: 0.140000\n",
      "Loss: 2.302333, Train accuracy: 0.184000, val accuracy: 0.200000\n",
      "Loss: 2.302271, Train accuracy: 0.178000, val accuracy: 0.230000\n",
      "Loss: 2.302205, Train accuracy: 0.183000, val accuracy: 0.220000\n",
      "Loss: 2.302151, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302094, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302049, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301992, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302330, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302281, Train accuracy: 0.147000, val accuracy: 0.120000\n",
      "Loss: 2.302212, Train accuracy: 0.151000, val accuracy: 0.140000\n",
      "Loss: 2.302157, Train accuracy: 0.176000, val accuracy: 0.210000\n",
      "Loss: 2.302076, Train accuracy: 0.186000, val accuracy: 0.230000\n",
      "Loss: 2.302015, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301948, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301922, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301848, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301798, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302418, Train accuracy: 0.107000, val accuracy: 0.100000\n",
      "Loss: 2.302371, Train accuracy: 0.120000, val accuracy: 0.130000\n",
      "Loss: 2.302293, Train accuracy: 0.148000, val accuracy: 0.120000\n",
      "Loss: 2.302239, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302154, Train accuracy: 0.152000, val accuracy: 0.130000\n",
      "Loss: 2.302092, Train accuracy: 0.171000, val accuracy: 0.180000\n",
      "Loss: 2.302018, Train accuracy: 0.184000, val accuracy: 0.240000\n",
      "Loss: 2.301938, Train accuracy: 0.185000, val accuracy: 0.240000\n",
      "Loss: 2.301870, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301797, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302653, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302595, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302528, Train accuracy: 0.108000, val accuracy: 0.200000\n",
      "Loss: 2.302452, Train accuracy: 0.171000, val accuracy: 0.210000\n",
      "Loss: 2.302379, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302311, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302241, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302166, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302113, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302037, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302547, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302482, Train accuracy: 0.068000, val accuracy: 0.060000\n",
      "Loss: 2.302412, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302343, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302282, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302193, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302144, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302057, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301978, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301919, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302638, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302588, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302533, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302505, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302472, Train accuracy: 0.099000, val accuracy: 0.060000\n",
      "Loss: 2.302453, Train accuracy: 0.146000, val accuracy: 0.170000\n",
      "Loss: 2.302448, Train accuracy: 0.161000, val accuracy: 0.220000\n",
      "Loss: 2.302422, Train accuracy: 0.164000, val accuracy: 0.210000\n",
      "Loss: 2.302415, Train accuracy: 0.176000, val accuracy: 0.230000\n",
      "Loss: 2.302420, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.302533, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302479, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302433, Train accuracy: 0.116000, val accuracy: 0.100000\n",
      "Loss: 2.302388, Train accuracy: 0.156000, val accuracy: 0.170000\n",
      "Loss: 2.302364, Train accuracy: 0.164000, val accuracy: 0.200000\n",
      "Loss: 2.302341, Train accuracy: 0.179000, val accuracy: 0.210000\n",
      "Loss: 2.302334, Train accuracy: 0.182000, val accuracy: 0.220000\n",
      "Loss: 2.302318, Train accuracy: 0.183000, val accuracy: 0.220000\n",
      "Loss: 2.302315, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.302307, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.302592, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302538, Train accuracy: 0.091000, val accuracy: 0.070000\n",
      "Loss: 2.302491, Train accuracy: 0.112000, val accuracy: 0.100000\n",
      "Loss: 2.302452, Train accuracy: 0.141000, val accuracy: 0.160000\n",
      "Loss: 2.302422, Train accuracy: 0.147000, val accuracy: 0.140000\n",
      "Loss: 2.302411, Train accuracy: 0.144000, val accuracy: 0.140000\n",
      "Loss: 2.302390, Train accuracy: 0.147000, val accuracy: 0.140000\n",
      "Loss: 2.302382, Train accuracy: 0.147000, val accuracy: 0.140000\n",
      "Loss: 2.302368, Train accuracy: 0.148000, val accuracy: 0.140000\n",
      "Loss: 2.302368, Train accuracy: 0.148000, val accuracy: 0.140000\n",
      "Loss: 2.302587, Train accuracy: 0.159000, val accuracy: 0.180000\n",
      "Loss: 2.302518, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302470, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302420, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302379, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302341, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302319, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302307, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302285, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302270, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302523, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302477, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302415, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302358, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302315, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302293, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302261, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302248, Train accuracy: 0.115000, val accuracy: 0.080000\n",
      "Loss: 2.302229, Train accuracy: 0.128000, val accuracy: 0.100000\n",
      "Loss: 2.302221, Train accuracy: 0.149000, val accuracy: 0.160000\n",
      "Loss: 2.302582, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302529, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.302476, Train accuracy: 0.070000, val accuracy: 0.060000\n",
      "Loss: 2.302417, Train accuracy: 0.176000, val accuracy: 0.210000\n",
      "Loss: 2.302388, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.302354, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.302323, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302304, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302286, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302276, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302527, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302471, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.302401, Train accuracy: 0.089000, val accuracy: 0.070000\n",
      "Loss: 2.302329, Train accuracy: 0.140000, val accuracy: 0.120000\n",
      "Loss: 2.302272, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302214, Train accuracy: 0.148000, val accuracy: 0.120000\n",
      "Loss: 2.302149, Train accuracy: 0.158000, val accuracy: 0.120000\n",
      "Loss: 2.302092, Train accuracy: 0.172000, val accuracy: 0.200000\n",
      "Loss: 2.302047, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.301992, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302616, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.302559, Train accuracy: 0.140000, val accuracy: 0.110000\n",
      "Loss: 2.302490, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302428, Train accuracy: 0.145000, val accuracy: 0.140000\n",
      "Loss: 2.302367, Train accuracy: 0.168000, val accuracy: 0.190000\n",
      "Loss: 2.302297, Train accuracy: 0.181000, val accuracy: 0.220000\n",
      "Loss: 2.302244, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302201, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302143, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302090, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302482, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302419, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302353, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302290, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302222, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302155, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302100, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302042, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.301988, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.301937, Train accuracy: 0.149000, val accuracy: 0.120000\n",
      "Loss: 2.302553, Train accuracy: 0.148000, val accuracy: 0.170000\n",
      "Loss: 2.302490, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302422, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302358, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302272, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302207, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302143, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302060, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301979, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301915, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302788, Train accuracy: 0.052000, val accuracy: 0.020000\n",
      "Loss: 2.302731, Train accuracy: 0.113000, val accuracy: 0.070000\n",
      "Loss: 2.302674, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302592, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.302520, Train accuracy: 0.110000, val accuracy: 0.070000\n",
      "Loss: 2.302453, Train accuracy: 0.106000, val accuracy: 0.060000\n",
      "Loss: 2.302382, Train accuracy: 0.137000, val accuracy: 0.060000\n",
      "Loss: 2.302302, Train accuracy: 0.145000, val accuracy: 0.100000\n",
      "Loss: 2.302235, Train accuracy: 0.145000, val accuracy: 0.120000\n",
      "Loss: 2.302167, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302447, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302388, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302330, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302253, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302174, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302105, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.302035, Train accuracy: 0.149000, val accuracy: 0.120000\n",
      "Loss: 2.301961, Train accuracy: 0.169000, val accuracy: 0.160000\n",
      "Loss: 2.301892, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301829, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303084, Train accuracy: 0.175000, val accuracy: 0.220000\n",
      "Loss: 2.303031, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302978, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302946, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302916, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302893, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302887, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302863, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302862, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302858, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303152, Train accuracy: 0.107000, val accuracy: 0.210000\n",
      "Loss: 2.303100, Train accuracy: 0.163000, val accuracy: 0.230000\n",
      "Loss: 2.303052, Train accuracy: 0.184000, val accuracy: 0.230000\n",
      "Loss: 2.303015, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302987, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302967, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302962, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302941, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302935, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302927, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303264, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.303209, Train accuracy: 0.093000, val accuracy: 0.080000\n",
      "Loss: 2.303161, Train accuracy: 0.111000, val accuracy: 0.090000\n",
      "Loss: 2.303119, Train accuracy: 0.130000, val accuracy: 0.160000\n",
      "Loss: 2.303095, Train accuracy: 0.173000, val accuracy: 0.210000\n",
      "Loss: 2.303076, Train accuracy: 0.182000, val accuracy: 0.220000\n",
      "Loss: 2.303054, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303051, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303042, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303039, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303196, Train accuracy: 0.180000, val accuracy: 0.230000\n",
      "Loss: 2.303150, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303084, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303048, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303001, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302966, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302941, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302927, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302900, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302892, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303387, Train accuracy: 0.062000, val accuracy: 0.040000\n",
      "Loss: 2.303336, Train accuracy: 0.066000, val accuracy: 0.050000\n",
      "Loss: 2.303273, Train accuracy: 0.095000, val accuracy: 0.100000\n",
      "Loss: 2.303232, Train accuracy: 0.148000, val accuracy: 0.120000\n",
      "Loss: 2.303190, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303156, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303132, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303111, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303097, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303077, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.303294, Train accuracy: 0.091000, val accuracy: 0.090000\n",
      "Loss: 2.303232, Train accuracy: 0.090000, val accuracy: 0.090000\n",
      "Loss: 2.303187, Train accuracy: 0.099000, val accuracy: 0.070000\n",
      "Loss: 2.303133, Train accuracy: 0.106000, val accuracy: 0.080000\n",
      "Loss: 2.303091, Train accuracy: 0.103000, val accuracy: 0.090000\n",
      "Loss: 2.303061, Train accuracy: 0.101000, val accuracy: 0.090000\n",
      "Loss: 2.303027, Train accuracy: 0.101000, val accuracy: 0.100000\n",
      "Loss: 2.303012, Train accuracy: 0.103000, val accuracy: 0.100000\n",
      "Loss: 2.303007, Train accuracy: 0.103000, val accuracy: 0.100000\n",
      "Loss: 2.302987, Train accuracy: 0.103000, val accuracy: 0.100000\n",
      "Loss: 2.303214, Train accuracy: 0.146000, val accuracy: 0.250000\n",
      "Loss: 2.303155, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303088, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303018, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302956, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302895, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302832, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302778, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302737, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302677, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303255, Train accuracy: 0.114000, val accuracy: 0.090000\n",
      "Loss: 2.303199, Train accuracy: 0.152000, val accuracy: 0.230000\n",
      "Loss: 2.303130, Train accuracy: 0.181000, val accuracy: 0.220000\n",
      "Loss: 2.303066, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302996, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302934, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302879, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302828, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302764, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302726, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303303, Train accuracy: 0.101000, val accuracy: 0.080000\n",
      "Loss: 2.303249, Train accuracy: 0.105000, val accuracy: 0.070000\n",
      "Loss: 2.303183, Train accuracy: 0.110000, val accuracy: 0.070000\n",
      "Loss: 2.303114, Train accuracy: 0.177000, val accuracy: 0.240000\n",
      "Loss: 2.303054, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302988, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302930, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302871, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302814, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302779, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303253, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303193, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303123, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303047, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302980, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302909, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302824, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302763, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302715, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302628, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303354, Train accuracy: 0.079000, val accuracy: 0.070000\n",
      "Loss: 2.303295, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.303227, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.303152, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.303088, Train accuracy: 0.142000, val accuracy: 0.160000\n",
      "Loss: 2.303011, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302942, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302869, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302800, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302731, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303322, Train accuracy: 0.058000, val accuracy: 0.030000\n",
      "Loss: 2.303266, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.303192, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303126, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303050, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302981, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302908, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302844, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302768, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302701, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341972, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341865, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341757, Train accuracy: 0.123000, val accuracy: 0.100000\n",
      "Loss: 2.341682, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.341617, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.341586, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.341550, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.341526, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.341522, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.341508, Train accuracy: 0.146000, val accuracy: 0.120000\n",
      "Loss: 2.342085, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.341974, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.341866, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.341784, Train accuracy: 0.067000, val accuracy: 0.050000\n",
      "Loss: 2.341735, Train accuracy: 0.094000, val accuracy: 0.070000\n",
      "Loss: 2.341695, Train accuracy: 0.114000, val accuracy: 0.080000\n",
      "Loss: 2.341662, Train accuracy: 0.137000, val accuracy: 0.120000\n",
      "Loss: 2.341643, Train accuracy: 0.141000, val accuracy: 0.120000\n",
      "Loss: 2.341633, Train accuracy: 0.142000, val accuracy: 0.110000\n",
      "Loss: 2.341623, Train accuracy: 0.147000, val accuracy: 0.110000\n",
      "Loss: 2.341975, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.341863, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.341758, Train accuracy: 0.056000, val accuracy: 0.030000\n",
      "Loss: 2.341682, Train accuracy: 0.077000, val accuracy: 0.060000\n",
      "Loss: 2.341621, Train accuracy: 0.110000, val accuracy: 0.090000\n",
      "Loss: 2.341588, Train accuracy: 0.135000, val accuracy: 0.130000\n",
      "Loss: 2.341560, Train accuracy: 0.147000, val accuracy: 0.120000\n",
      "Loss: 2.341526, Train accuracy: 0.148000, val accuracy: 0.120000\n",
      "Loss: 2.341519, Train accuracy: 0.147000, val accuracy: 0.120000\n",
      "Loss: 2.341515, Train accuracy: 0.147000, val accuracy: 0.120000\n",
      "Loss: 2.342129, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.342020, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341902, Train accuracy: 0.080000, val accuracy: 0.070000\n",
      "Loss: 2.341801, Train accuracy: 0.081000, val accuracy: 0.070000\n",
      "Loss: 2.341711, Train accuracy: 0.082000, val accuracy: 0.070000\n",
      "Loss: 2.341645, Train accuracy: 0.090000, val accuracy: 0.060000\n",
      "Loss: 2.341595, Train accuracy: 0.093000, val accuracy: 0.060000\n",
      "Loss: 2.341551, Train accuracy: 0.104000, val accuracy: 0.050000\n",
      "Loss: 2.341523, Train accuracy: 0.107000, val accuracy: 0.050000\n",
      "Loss: 2.341498, Train accuracy: 0.107000, val accuracy: 0.050000\n",
      "Loss: 2.342274, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342168, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342045, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341955, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341861, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341802, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341755, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341704, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341678, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.341652, Train accuracy: 0.104000, val accuracy: 0.090000\n",
      "Loss: 2.342269, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.342150, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.342034, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341930, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341856, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341782, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341737, Train accuracy: 0.117000, val accuracy: 0.070000\n",
      "Loss: 2.341686, Train accuracy: 0.144000, val accuracy: 0.110000\n",
      "Loss: 2.341662, Train accuracy: 0.172000, val accuracy: 0.220000\n",
      "Loss: 2.341631, Train accuracy: 0.179000, val accuracy: 0.230000\n",
      "Loss: 2.341907, Train accuracy: 0.091000, val accuracy: 0.070000\n",
      "Loss: 2.341792, Train accuracy: 0.121000, val accuracy: 0.140000\n",
      "Loss: 2.341652, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341512, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341383, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341260, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341144, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341028, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340920, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340818, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341906, Train accuracy: 0.183000, val accuracy: 0.240000\n",
      "Loss: 2.341797, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.341657, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341520, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341390, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341254, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341142, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341031, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340908, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340817, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.342092, Train accuracy: 0.059000, val accuracy: 0.080000\n",
      "Loss: 2.341979, Train accuracy: 0.062000, val accuracy: 0.090000\n",
      "Loss: 2.341839, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341701, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341573, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341444, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341324, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341198, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341111, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341003, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.342073, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341967, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341823, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341664, Train accuracy: 0.090000, val accuracy: 0.070000\n",
      "Loss: 2.341517, Train accuracy: 0.122000, val accuracy: 0.100000\n",
      "Loss: 2.341380, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.341227, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341083, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340932, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340795, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341853, Train accuracy: 0.111000, val accuracy: 0.070000\n",
      "Loss: 2.341735, Train accuracy: 0.112000, val accuracy: 0.070000\n",
      "Loss: 2.341597, Train accuracy: 0.173000, val accuracy: 0.190000\n",
      "Loss: 2.341454, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341305, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341157, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341011, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340883, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340711, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340587, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.342275, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342156, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.342006, Train accuracy: 0.063000, val accuracy: 0.040000\n",
      "Loss: 2.341860, Train accuracy: 0.064000, val accuracy: 0.050000\n",
      "Loss: 2.341711, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341559, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341406, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341271, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.341140, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340989, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301898, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298934, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296093, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294231, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293074, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291840, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291294, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290929, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290441, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290391, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301748, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298723, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296212, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294259, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292807, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291778, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291099, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290878, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290372, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290020, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302072, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299109, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296448, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294477, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293122, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292183, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291371, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290939, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290533, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290423, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301914, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298785, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295925, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293609, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291520, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289760, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288925, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287913, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287264, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286504, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301712, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298649, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295752, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293279, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291007, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289483, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288396, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287573, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286763, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286352, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301778, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298832, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295932, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293279, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291234, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289932, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288576, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287991, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286957, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286748, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301875, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298783, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295262, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291646, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288712, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285892, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283681, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.280961, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279210, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277212, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301652, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298531, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295329, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291753, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288865, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285887, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283730, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281252, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279406, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277067, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301887, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298839, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295298, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291997, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289080, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285972, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283528, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281704, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279114, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277484, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301587, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298413, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294732, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291206, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287768, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284796, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281530, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278743, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276011, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273549, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301830, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298580, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294963, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291205, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287673, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284463, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281911, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279503, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276372, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273067, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301813, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298634, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294887, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291455, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288322, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284864, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281981, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279162, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276577, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.274214, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301789, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298811, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296086, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294105, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292557, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291884, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291103, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290614, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290077, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289980, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301818, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298822, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296023, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294289, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292705, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291885, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291367, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290634, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290317, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290383, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302034, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299137, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296399, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294489, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293127, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291866, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291418, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291208, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290750, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290387, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301849, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298838, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295755, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293472, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291429, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289756, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288774, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287903, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286918, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286733, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301742, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298605, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295622, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293280, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291079, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289860, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288634, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287530, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287103, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286698, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301787, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298885, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295786, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293281, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291403, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289774, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288632, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287693, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287258, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286919, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301962, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298839, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295225, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291710, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288594, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286361, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283350, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281125, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279194, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277049, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301780, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298746, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295017, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291796, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288593, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286135, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283502, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281289, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279265, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277191, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302002, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298979, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295568, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292021, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288877, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286136, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283666, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281695, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279574, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277664, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302006, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298840, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295196, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291860, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288204, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285363, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.282062, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279372, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276725, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273815, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301924, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298738, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295074, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291376, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287985, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284621, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.282201, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278947, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276588, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.274182, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301822, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298658, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295020, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291496, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287959, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284899, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281919, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278789, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276494, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273428, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301863, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298999, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296322, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294193, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292802, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291821, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291254, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290881, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290689, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290142, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301933, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299098, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296299, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294337, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293034, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291832, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291330, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290642, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290533, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290628, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302062, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299085, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296470, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294599, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292924, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292186, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291550, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291058, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290763, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290400, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301927, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298807, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296011, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293086, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291508, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289642, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288624, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288006, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286956, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286428, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301824, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298866, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295752, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293215, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291332, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289792, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288634, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287867, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286885, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286470, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301847, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298924, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295762, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293393, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291578, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289760, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288959, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287995, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286929, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286640, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301966, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298819, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295220, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291962, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288756, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286415, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283422, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281381, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278897, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277463, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301731, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298644, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295106, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291685, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288870, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285930, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283552, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281191, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278856, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277421, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302111, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298823, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295479, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291957, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288483, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285997, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283645, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.280917, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279216, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277156, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301888, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298890, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295209, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291182, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287866, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284724, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281973, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278823, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276244, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273596, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301773, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298653, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294758, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290938, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287718, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284638, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281162, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278684, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276661, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273330, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301770, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298669, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294991, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291135, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287975, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284471, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.282222, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278421, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276100, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273932, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302525, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299515, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296974, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294822, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293330, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292463, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291895, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291513, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291074, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291097, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302394, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299535, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296816, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294728, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293556, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292618, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291881, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291149, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291175, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290982, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302547, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299603, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296974, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294826, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293651, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292579, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292061, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291686, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291061, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290937, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302555, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299605, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296219, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294059, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292052, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290492, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289377, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288652, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287373, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287201, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302436, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299484, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296453, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293927, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291965, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290555, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289478, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288448, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287375, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286979, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302810, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299904, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296703, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294464, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292422, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291121, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289624, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288692, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288259, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287327, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302603, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299423, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295861, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292726, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289474, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286440, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284600, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.282229, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279531, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278818, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302425, Train accuracy: 0.145000, val accuracy: 0.130000\n",
      "Loss: 2.299495, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295805, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292475, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289766, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286528, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284314, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281869, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279786, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277847, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302606, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299363, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295704, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292508, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289623, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286593, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284414, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281825, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.280631, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277838, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302442, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299363, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295721, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292171, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288679, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285906, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.282494, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279750, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277426, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.275266, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302484, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299382, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295730, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292323, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288936, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285668, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.282689, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279734, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276774, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.274946, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302638, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299582, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295818, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.292306, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288231, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285565, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.282622, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278996, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276844, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.275202, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340567, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334788, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.329553, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.325933, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.323649, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.322243, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.320879, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.320309, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.319811, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.319497, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340183, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334439, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.329013, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.325719, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.323359, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321849, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.320693, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.320083, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.319301, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.319087, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340296, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334410, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.329458, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.325780, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.323499, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321953, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.320877, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.320096, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.319792, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.319242, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340611, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334625, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.328936, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.324658, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321153, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.318946, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.317178, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.315521, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.314570, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.313639, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340386, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334653, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.328555, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.324134, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321175, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.318646, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.317081, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.315432, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.314051, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.313623, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340588, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334781, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.328862, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.324456, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321300, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.318635, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.317005, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.315865, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.314362, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.313783, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340570, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334312, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.327847, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321865, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.316935, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.312910, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.309346, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.306273, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303931, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301503, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340244, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334086, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.327456, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321479, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.316512, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.312419, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.308879, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.306284, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303729, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.300756, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340431, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334184, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.327547, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321639, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.316934, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.312941, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.309100, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.306667, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303906, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301465, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340521, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334208, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.327260, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321190, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.315559, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.311052, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.306869, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.304062, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.300781, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.297308, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340408, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334076, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.327229, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321028, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.315551, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.310748, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.307246, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302685, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.300284, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.297814, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.340430, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334424, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.327129, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321114, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.315688, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.311342, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.306742, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303550, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.300038, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.297755, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.274831, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.237898, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.229464, Train accuracy: 0.184000, val accuracy: 0.210000\n",
      "Loss: 2.221986, Train accuracy: 0.193000, val accuracy: 0.200000\n",
      "Loss: 2.208948, Train accuracy: 0.198000, val accuracy: 0.200000\n",
      "Loss: 2.193728, Train accuracy: 0.205000, val accuracy: 0.220000\n",
      "Loss: 2.180270, Train accuracy: 0.205000, val accuracy: 0.180000\n",
      "Loss: 2.173354, Train accuracy: 0.214000, val accuracy: 0.190000\n",
      "Loss: 2.165017, Train accuracy: 0.216000, val accuracy: 0.190000\n",
      "Loss: 2.157604, Train accuracy: 0.223000, val accuracy: 0.200000\n",
      "Loss: 2.277666, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.233495, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.229149, Train accuracy: 0.180000, val accuracy: 0.240000\n",
      "Loss: 2.218265, Train accuracy: 0.187000, val accuracy: 0.220000\n",
      "Loss: 2.204495, Train accuracy: 0.205000, val accuracy: 0.210000\n",
      "Loss: 2.186812, Train accuracy: 0.210000, val accuracy: 0.180000\n",
      "Loss: 2.180914, Train accuracy: 0.209000, val accuracy: 0.190000\n",
      "Loss: 2.170421, Train accuracy: 0.217000, val accuracy: 0.190000\n",
      "Loss: 2.155037, Train accuracy: 0.224000, val accuracy: 0.200000\n",
      "Loss: 2.153926, Train accuracy: 0.230000, val accuracy: 0.210000\n",
      "Loss: 2.271338, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.232249, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.232914, Train accuracy: 0.188000, val accuracy: 0.250000\n",
      "Loss: 2.219622, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.200423, Train accuracy: 0.199000, val accuracy: 0.210000\n",
      "Loss: 2.182436, Train accuracy: 0.195000, val accuracy: 0.190000\n",
      "Loss: 2.171612, Train accuracy: 0.208000, val accuracy: 0.190000\n",
      "Loss: 2.164864, Train accuracy: 0.214000, val accuracy: 0.210000\n",
      "Loss: 2.155332, Train accuracy: 0.222000, val accuracy: 0.220000\n",
      "Loss: 2.152330, Train accuracy: 0.231000, val accuracy: 0.220000\n",
      "Loss: 2.271519, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.234553, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.229638, Train accuracy: 0.186000, val accuracy: 0.220000\n",
      "Loss: 2.212788, Train accuracy: 0.194000, val accuracy: 0.240000\n",
      "Loss: 2.194006, Train accuracy: 0.222000, val accuracy: 0.210000\n",
      "Loss: 2.156205, Train accuracy: 0.255000, val accuracy: 0.280000\n",
      "Loss: 2.118620, Train accuracy: 0.269000, val accuracy: 0.270000\n",
      "Loss: 2.081756, Train accuracy: 0.260000, val accuracy: 0.300000\n",
      "Loss: 2.042655, Train accuracy: 0.300000, val accuracy: 0.330000\n",
      "Loss: 2.008569, Train accuracy: 0.301000, val accuracy: 0.320000\n",
      "Loss: 2.275101, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.235877, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.226296, Train accuracy: 0.191000, val accuracy: 0.190000\n",
      "Loss: 2.203952, Train accuracy: 0.197000, val accuracy: 0.180000\n",
      "Loss: 2.181646, Train accuracy: 0.204000, val accuracy: 0.200000\n",
      "Loss: 2.159499, Train accuracy: 0.219000, val accuracy: 0.220000\n",
      "Loss: 2.132330, Train accuracy: 0.259000, val accuracy: 0.260000\n",
      "Loss: 2.095782, Train accuracy: 0.288000, val accuracy: 0.280000\n",
      "Loss: 2.060275, Train accuracy: 0.300000, val accuracy: 0.290000\n",
      "Loss: 2.016996, Train accuracy: 0.308000, val accuracy: 0.300000\n",
      "Loss: 2.275005, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.233975, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.229325, Train accuracy: 0.197000, val accuracy: 0.200000\n",
      "Loss: 2.214286, Train accuracy: 0.206000, val accuracy: 0.190000\n",
      "Loss: 2.184746, Train accuracy: 0.228000, val accuracy: 0.240000\n",
      "Loss: 2.154021, Train accuracy: 0.259000, val accuracy: 0.270000\n",
      "Loss: 2.119704, Train accuracy: 0.277000, val accuracy: 0.290000\n",
      "Loss: 2.084747, Train accuracy: 0.282000, val accuracy: 0.300000\n",
      "Loss: 2.039913, Train accuracy: 0.301000, val accuracy: 0.300000\n",
      "Loss: 2.011534, Train accuracy: 0.314000, val accuracy: 0.330000\n",
      "Loss: 2.272722, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.242017, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.237065, Train accuracy: 0.188000, val accuracy: 0.180000\n",
      "Loss: 2.226537, Train accuracy: 0.192000, val accuracy: 0.220000\n",
      "Loss: 2.202334, Train accuracy: 0.211000, val accuracy: 0.210000\n",
      "Loss: 2.142111, Train accuracy: 0.277000, val accuracy: 0.280000\n",
      "Loss: 2.027800, Train accuracy: 0.356000, val accuracy: 0.300000\n",
      "Loss: 1.886715, Train accuracy: 0.409000, val accuracy: 0.340000\n",
      "Loss: 1.681324, Train accuracy: 0.506000, val accuracy: 0.360000\n",
      "Loss: 1.514577, Train accuracy: 0.507000, val accuracy: 0.330000\n",
      "Loss: 2.274193, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.242681, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.224678, Train accuracy: 0.189000, val accuracy: 0.180000\n",
      "Loss: 2.205563, Train accuracy: 0.216000, val accuracy: 0.220000\n",
      "Loss: 2.152692, Train accuracy: 0.266000, val accuracy: 0.270000\n",
      "Loss: 2.097648, Train accuracy: 0.291000, val accuracy: 0.280000\n",
      "Loss: 1.994551, Train accuracy: 0.308000, val accuracy: 0.280000\n",
      "Loss: 1.882830, Train accuracy: 0.391000, val accuracy: 0.320000\n",
      "Loss: 1.762639, Train accuracy: 0.461000, val accuracy: 0.320000\n",
      "Loss: 1.561972, Train accuracy: 0.498000, val accuracy: 0.400000\n",
      "Loss: 2.272015, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.236910, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.227636, Train accuracy: 0.194000, val accuracy: 0.200000\n",
      "Loss: 2.219203, Train accuracy: 0.209000, val accuracy: 0.210000\n",
      "Loss: 2.185398, Train accuracy: 0.246000, val accuracy: 0.240000\n",
      "Loss: 2.106387, Train accuracy: 0.291000, val accuracy: 0.310000\n",
      "Loss: 1.982948, Train accuracy: 0.369000, val accuracy: 0.330000\n",
      "Loss: 1.845614, Train accuracy: 0.445000, val accuracy: 0.330000\n",
      "Loss: 1.642515, Train accuracy: 0.509000, val accuracy: 0.390000\n",
      "Loss: 1.472324, Train accuracy: 0.530000, val accuracy: 0.350000\n",
      "Loss: 2.276814, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.230595, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.234377, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.200685, Train accuracy: 0.203000, val accuracy: 0.190000\n",
      "Loss: 2.169813, Train accuracy: 0.264000, val accuracy: 0.240000\n",
      "Loss: 2.081284, Train accuracy: 0.281000, val accuracy: 0.290000\n",
      "Loss: 1.956238, Train accuracy: 0.393000, val accuracy: 0.300000\n",
      "Loss: 1.736800, Train accuracy: 0.501000, val accuracy: 0.340000\n",
      "Loss: 1.540763, Train accuracy: 0.556000, val accuracy: 0.340000\n",
      "Loss: 1.371852, Train accuracy: 0.509000, val accuracy: 0.360000\n",
      "Loss: 2.273393, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.236196, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.228109, Train accuracy: 0.194000, val accuracy: 0.200000\n",
      "Loss: 2.203971, Train accuracy: 0.174000, val accuracy: 0.170000\n",
      "Loss: 2.159426, Train accuracy: 0.260000, val accuracy: 0.250000\n",
      "Loss: 2.083057, Train accuracy: 0.309000, val accuracy: 0.310000\n",
      "Loss: 1.954700, Train accuracy: 0.379000, val accuracy: 0.300000\n",
      "Loss: 1.759508, Train accuracy: 0.446000, val accuracy: 0.330000\n",
      "Loss: 1.584567, Train accuracy: 0.512000, val accuracy: 0.370000\n",
      "Loss: 1.484503, Train accuracy: 0.572000, val accuracy: 0.480000\n",
      "Loss: 2.270558, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.236698, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.224156, Train accuracy: 0.190000, val accuracy: 0.210000\n",
      "Loss: 2.209335, Train accuracy: 0.211000, val accuracy: 0.190000\n",
      "Loss: 2.169304, Train accuracy: 0.268000, val accuracy: 0.270000\n",
      "Loss: 2.093958, Train accuracy: 0.316000, val accuracy: 0.290000\n",
      "Loss: 1.982063, Train accuracy: 0.404000, val accuracy: 0.310000\n",
      "Loss: 1.747421, Train accuracy: 0.449000, val accuracy: 0.360000\n",
      "Loss: 1.571168, Train accuracy: 0.489000, val accuracy: 0.370000\n",
      "Loss: 1.545120, Train accuracy: 0.530000, val accuracy: 0.360000\n",
      "Loss: 2.274016, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.241114, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.229836, Train accuracy: 0.187000, val accuracy: 0.260000\n",
      "Loss: 2.221756, Train accuracy: 0.189000, val accuracy: 0.250000\n",
      "Loss: 2.209728, Train accuracy: 0.193000, val accuracy: 0.210000\n",
      "Loss: 2.197542, Train accuracy: 0.201000, val accuracy: 0.200000\n",
      "Loss: 2.185917, Train accuracy: 0.207000, val accuracy: 0.200000\n",
      "Loss: 2.176973, Train accuracy: 0.208000, val accuracy: 0.180000\n",
      "Loss: 2.168698, Train accuracy: 0.217000, val accuracy: 0.190000\n",
      "Loss: 2.163682, Train accuracy: 0.223000, val accuracy: 0.200000\n",
      "Loss: 2.272413, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.234507, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.229252, Train accuracy: 0.184000, val accuracy: 0.220000\n",
      "Loss: 2.216704, Train accuracy: 0.184000, val accuracy: 0.210000\n",
      "Loss: 2.200804, Train accuracy: 0.198000, val accuracy: 0.190000\n",
      "Loss: 2.186446, Train accuracy: 0.203000, val accuracy: 0.190000\n",
      "Loss: 2.171812, Train accuracy: 0.207000, val accuracy: 0.200000\n",
      "Loss: 2.164608, Train accuracy: 0.207000, val accuracy: 0.200000\n",
      "Loss: 2.161625, Train accuracy: 0.211000, val accuracy: 0.200000\n",
      "Loss: 2.154118, Train accuracy: 0.217000, val accuracy: 0.200000\n",
      "Loss: 2.274791, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.232849, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.227504, Train accuracy: 0.185000, val accuracy: 0.200000\n",
      "Loss: 2.221012, Train accuracy: 0.198000, val accuracy: 0.200000\n",
      "Loss: 2.206116, Train accuracy: 0.194000, val accuracy: 0.190000\n",
      "Loss: 2.188116, Train accuracy: 0.203000, val accuracy: 0.220000\n",
      "Loss: 2.178576, Train accuracy: 0.204000, val accuracy: 0.190000\n",
      "Loss: 2.168829, Train accuracy: 0.209000, val accuracy: 0.200000\n",
      "Loss: 2.159616, Train accuracy: 0.217000, val accuracy: 0.190000\n",
      "Loss: 2.157429, Train accuracy: 0.216000, val accuracy: 0.190000\n",
      "Loss: 2.272886, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.232488, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.229405, Train accuracy: 0.183000, val accuracy: 0.210000\n",
      "Loss: 2.208542, Train accuracy: 0.199000, val accuracy: 0.200000\n",
      "Loss: 2.185496, Train accuracy: 0.216000, val accuracy: 0.200000\n",
      "Loss: 2.154798, Train accuracy: 0.245000, val accuracy: 0.240000\n",
      "Loss: 2.125096, Train accuracy: 0.272000, val accuracy: 0.280000\n",
      "Loss: 2.078671, Train accuracy: 0.282000, val accuracy: 0.290000\n",
      "Loss: 2.041001, Train accuracy: 0.306000, val accuracy: 0.310000\n",
      "Loss: 2.004531, Train accuracy: 0.316000, val accuracy: 0.300000\n",
      "Loss: 2.273294, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.231434, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.226315, Train accuracy: 0.193000, val accuracy: 0.190000\n",
      "Loss: 2.213676, Train accuracy: 0.177000, val accuracy: 0.180000\n",
      "Loss: 2.193265, Train accuracy: 0.217000, val accuracy: 0.220000\n",
      "Loss: 2.162043, Train accuracy: 0.250000, val accuracy: 0.260000\n",
      "Loss: 2.131413, Train accuracy: 0.286000, val accuracy: 0.270000\n",
      "Loss: 2.095187, Train accuracy: 0.292000, val accuracy: 0.310000\n",
      "Loss: 2.045547, Train accuracy: 0.298000, val accuracy: 0.310000\n",
      "Loss: 2.012483, Train accuracy: 0.316000, val accuracy: 0.310000\n",
      "Loss: 2.272760, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.235005, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.229170, Train accuracy: 0.183000, val accuracy: 0.220000\n",
      "Loss: 2.210732, Train accuracy: 0.171000, val accuracy: 0.160000\n",
      "Loss: 2.187486, Train accuracy: 0.204000, val accuracy: 0.200000\n",
      "Loss: 2.166116, Train accuracy: 0.225000, val accuracy: 0.210000\n",
      "Loss: 2.139785, Train accuracy: 0.247000, val accuracy: 0.230000\n",
      "Loss: 2.115430, Train accuracy: 0.280000, val accuracy: 0.280000\n",
      "Loss: 2.081341, Train accuracy: 0.288000, val accuracy: 0.290000\n",
      "Loss: 2.049419, Train accuracy: 0.295000, val accuracy: 0.320000\n",
      "Loss: 2.273765, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.235683, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.222735, Train accuracy: 0.187000, val accuracy: 0.210000\n",
      "Loss: 2.197355, Train accuracy: 0.211000, val accuracy: 0.180000\n",
      "Loss: 2.188219, Train accuracy: 0.260000, val accuracy: 0.260000\n",
      "Loss: 2.093978, Train accuracy: 0.281000, val accuracy: 0.280000\n",
      "Loss: 1.964652, Train accuracy: 0.366000, val accuracy: 0.300000\n",
      "Loss: 1.819151, Train accuracy: 0.452000, val accuracy: 0.380000\n",
      "Loss: 1.685909, Train accuracy: 0.486000, val accuracy: 0.350000\n",
      "Loss: 1.532372, Train accuracy: 0.512000, val accuracy: 0.360000\n",
      "Loss: 2.270918, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.239671, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.232168, Train accuracy: 0.194000, val accuracy: 0.190000\n",
      "Loss: 2.211801, Train accuracy: 0.192000, val accuracy: 0.200000\n",
      "Loss: 2.173416, Train accuracy: 0.235000, val accuracy: 0.230000\n",
      "Loss: 2.111359, Train accuracy: 0.291000, val accuracy: 0.310000\n",
      "Loss: 2.017214, Train accuracy: 0.328000, val accuracy: 0.280000\n",
      "Loss: 1.876016, Train accuracy: 0.365000, val accuracy: 0.290000\n",
      "Loss: 1.727569, Train accuracy: 0.462000, val accuracy: 0.340000\n",
      "Loss: 1.508667, Train accuracy: 0.533000, val accuracy: 0.370000\n",
      "Loss: 2.271953, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.238012, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.226578, Train accuracy: 0.190000, val accuracy: 0.190000\n",
      "Loss: 2.200506, Train accuracy: 0.207000, val accuracy: 0.190000\n",
      "Loss: 2.169066, Train accuracy: 0.266000, val accuracy: 0.260000\n",
      "Loss: 2.097615, Train accuracy: 0.295000, val accuracy: 0.290000\n",
      "Loss: 1.979849, Train accuracy: 0.364000, val accuracy: 0.330000\n",
      "Loss: 1.785752, Train accuracy: 0.425000, val accuracy: 0.320000\n",
      "Loss: 1.655557, Train accuracy: 0.499000, val accuracy: 0.360000\n",
      "Loss: 1.484330, Train accuracy: 0.491000, val accuracy: 0.310000\n",
      "Loss: 2.274298, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.233810, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.225696, Train accuracy: 0.187000, val accuracy: 0.230000\n",
      "Loss: 2.199163, Train accuracy: 0.203000, val accuracy: 0.180000\n",
      "Loss: 2.169939, Train accuracy: 0.232000, val accuracy: 0.220000\n",
      "Loss: 2.069415, Train accuracy: 0.325000, val accuracy: 0.330000\n",
      "Loss: 1.920047, Train accuracy: 0.400000, val accuracy: 0.360000\n",
      "Loss: 1.685361, Train accuracy: 0.477000, val accuracy: 0.330000\n",
      "Loss: 1.624881, Train accuracy: 0.467000, val accuracy: 0.360000\n",
      "Loss: 1.555046, Train accuracy: 0.511000, val accuracy: 0.390000\n",
      "Loss: 2.277073, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.238256, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.227371, Train accuracy: 0.204000, val accuracy: 0.220000\n",
      "Loss: 2.201574, Train accuracy: 0.220000, val accuracy: 0.190000\n",
      "Loss: 2.151414, Train accuracy: 0.248000, val accuracy: 0.270000\n",
      "Loss: 2.088122, Train accuracy: 0.305000, val accuracy: 0.290000\n",
      "Loss: 1.935811, Train accuracy: 0.376000, val accuracy: 0.290000\n",
      "Loss: 1.786231, Train accuracy: 0.451000, val accuracy: 0.320000\n",
      "Loss: 1.736083, Train accuracy: 0.441000, val accuracy: 0.340000\n",
      "Loss: 1.542054, Train accuracy: 0.530000, val accuracy: 0.370000\n",
      "Loss: 2.276378, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.242110, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.223935, Train accuracy: 0.189000, val accuracy: 0.270000\n",
      "Loss: 2.196474, Train accuracy: 0.198000, val accuracy: 0.170000\n",
      "Loss: 2.157325, Train accuracy: 0.239000, val accuracy: 0.250000\n",
      "Loss: 2.093310, Train accuracy: 0.355000, val accuracy: 0.310000\n",
      "Loss: 1.891156, Train accuracy: 0.356000, val accuracy: 0.320000\n",
      "Loss: 1.668638, Train accuracy: 0.480000, val accuracy: 0.390000\n",
      "Loss: 1.525462, Train accuracy: 0.506000, val accuracy: 0.380000\n",
      "Loss: 1.461978, Train accuracy: 0.536000, val accuracy: 0.430000\n",
      "Loss: 2.275443, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.229597, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.227428, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.221939, Train accuracy: 0.183000, val accuracy: 0.210000\n",
      "Loss: 2.202735, Train accuracy: 0.196000, val accuracy: 0.200000\n",
      "Loss: 2.186422, Train accuracy: 0.203000, val accuracy: 0.180000\n",
      "Loss: 2.178174, Train accuracy: 0.205000, val accuracy: 0.190000\n",
      "Loss: 2.164117, Train accuracy: 0.212000, val accuracy: 0.180000\n",
      "Loss: 2.158847, Train accuracy: 0.216000, val accuracy: 0.210000\n",
      "Loss: 2.150719, Train accuracy: 0.223000, val accuracy: 0.210000\n",
      "Loss: 2.276058, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.232270, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.226394, Train accuracy: 0.185000, val accuracy: 0.220000\n",
      "Loss: 2.214794, Train accuracy: 0.195000, val accuracy: 0.200000\n",
      "Loss: 2.203841, Train accuracy: 0.199000, val accuracy: 0.210000\n",
      "Loss: 2.188169, Train accuracy: 0.183000, val accuracy: 0.190000\n",
      "Loss: 2.176977, Train accuracy: 0.216000, val accuracy: 0.190000\n",
      "Loss: 2.165020, Train accuracy: 0.225000, val accuracy: 0.200000\n",
      "Loss: 2.157582, Train accuracy: 0.229000, val accuracy: 0.210000\n",
      "Loss: 2.151353, Train accuracy: 0.235000, val accuracy: 0.230000\n",
      "Loss: 2.271773, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.237141, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.226875, Train accuracy: 0.186000, val accuracy: 0.200000\n",
      "Loss: 2.216311, Train accuracy: 0.190000, val accuracy: 0.210000\n",
      "Loss: 2.202062, Train accuracy: 0.202000, val accuracy: 0.200000\n",
      "Loss: 2.185207, Train accuracy: 0.208000, val accuracy: 0.220000\n",
      "Loss: 2.178342, Train accuracy: 0.216000, val accuracy: 0.190000\n",
      "Loss: 2.167799, Train accuracy: 0.231000, val accuracy: 0.210000\n",
      "Loss: 2.156845, Train accuracy: 0.236000, val accuracy: 0.220000\n",
      "Loss: 2.155284, Train accuracy: 0.238000, val accuracy: 0.230000\n",
      "Loss: 2.270859, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.239255, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.227909, Train accuracy: 0.193000, val accuracy: 0.200000\n",
      "Loss: 2.212369, Train accuracy: 0.194000, val accuracy: 0.250000\n",
      "Loss: 2.182498, Train accuracy: 0.225000, val accuracy: 0.190000\n",
      "Loss: 2.152472, Train accuracy: 0.259000, val accuracy: 0.250000\n",
      "Loss: 2.123321, Train accuracy: 0.286000, val accuracy: 0.300000\n",
      "Loss: 2.074354, Train accuracy: 0.301000, val accuracy: 0.310000\n",
      "Loss: 2.032123, Train accuracy: 0.304000, val accuracy: 0.330000\n",
      "Loss: 2.012188, Train accuracy: 0.318000, val accuracy: 0.310000\n",
      "Loss: 2.271574, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.234833, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.225832, Train accuracy: 0.191000, val accuracy: 0.190000\n",
      "Loss: 2.214379, Train accuracy: 0.192000, val accuracy: 0.200000\n",
      "Loss: 2.197147, Train accuracy: 0.226000, val accuracy: 0.250000\n",
      "Loss: 2.175345, Train accuracy: 0.240000, val accuracy: 0.230000\n",
      "Loss: 2.143477, Train accuracy: 0.255000, val accuracy: 0.250000\n",
      "Loss: 2.098720, Train accuracy: 0.264000, val accuracy: 0.270000\n",
      "Loss: 2.050911, Train accuracy: 0.307000, val accuracy: 0.310000\n",
      "Loss: 2.013441, Train accuracy: 0.321000, val accuracy: 0.290000\n",
      "Loss: 2.276130, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.231668, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.230626, Train accuracy: 0.196000, val accuracy: 0.200000\n",
      "Loss: 2.215529, Train accuracy: 0.196000, val accuracy: 0.210000\n",
      "Loss: 2.196225, Train accuracy: 0.209000, val accuracy: 0.190000\n",
      "Loss: 2.175263, Train accuracy: 0.220000, val accuracy: 0.230000\n",
      "Loss: 2.138978, Train accuracy: 0.272000, val accuracy: 0.270000\n",
      "Loss: 2.101795, Train accuracy: 0.287000, val accuracy: 0.280000\n",
      "Loss: 2.061718, Train accuracy: 0.307000, val accuracy: 0.300000\n",
      "Loss: 2.011653, Train accuracy: 0.326000, val accuracy: 0.310000\n",
      "Loss: 2.269790, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.234702, Train accuracy: 0.184000, val accuracy: 0.230000\n",
      "Loss: 2.226796, Train accuracy: 0.187000, val accuracy: 0.210000\n",
      "Loss: 2.214670, Train accuracy: 0.207000, val accuracy: 0.230000\n",
      "Loss: 2.167504, Train accuracy: 0.258000, val accuracy: 0.260000\n",
      "Loss: 2.084312, Train accuracy: 0.297000, val accuracy: 0.300000\n",
      "Loss: 1.948814, Train accuracy: 0.409000, val accuracy: 0.340000\n",
      "Loss: 1.768839, Train accuracy: 0.465000, val accuracy: 0.360000\n",
      "Loss: 1.591218, Train accuracy: 0.482000, val accuracy: 0.370000\n",
      "Loss: 1.522686, Train accuracy: 0.502000, val accuracy: 0.360000\n",
      "Loss: 2.273118, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.242072, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.227868, Train accuracy: 0.194000, val accuracy: 0.200000\n",
      "Loss: 2.217929, Train accuracy: 0.209000, val accuracy: 0.220000\n",
      "Loss: 2.187374, Train accuracy: 0.258000, val accuracy: 0.260000\n",
      "Loss: 2.102188, Train accuracy: 0.308000, val accuracy: 0.280000\n",
      "Loss: 1.965426, Train accuracy: 0.365000, val accuracy: 0.340000\n",
      "Loss: 1.801311, Train accuracy: 0.441000, val accuracy: 0.350000\n",
      "Loss: 1.611679, Train accuracy: 0.460000, val accuracy: 0.340000\n",
      "Loss: 1.538863, Train accuracy: 0.557000, val accuracy: 0.390000\n",
      "Loss: 2.273751, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.239979, Train accuracy: 0.184000, val accuracy: 0.260000\n",
      "Loss: 2.227495, Train accuracy: 0.189000, val accuracy: 0.240000\n",
      "Loss: 2.208493, Train accuracy: 0.203000, val accuracy: 0.200000\n",
      "Loss: 2.170337, Train accuracy: 0.271000, val accuracy: 0.270000\n",
      "Loss: 2.077923, Train accuracy: 0.289000, val accuracy: 0.300000\n",
      "Loss: 1.962752, Train accuracy: 0.394000, val accuracy: 0.330000\n",
      "Loss: 1.843694, Train accuracy: 0.406000, val accuracy: 0.320000\n",
      "Loss: 1.697361, Train accuracy: 0.479000, val accuracy: 0.370000\n",
      "Loss: 1.508562, Train accuracy: 0.536000, val accuracy: 0.400000\n",
      "Loss: 2.274023, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.232861, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.230487, Train accuracy: 0.188000, val accuracy: 0.210000\n",
      "Loss: 2.198799, Train accuracy: 0.214000, val accuracy: 0.210000\n",
      "Loss: 2.185049, Train accuracy: 0.251000, val accuracy: 0.230000\n",
      "Loss: 2.109057, Train accuracy: 0.251000, val accuracy: 0.260000\n",
      "Loss: 2.031249, Train accuracy: 0.404000, val accuracy: 0.360000\n",
      "Loss: 1.807600, Train accuracy: 0.465000, val accuracy: 0.350000\n",
      "Loss: 1.588993, Train accuracy: 0.477000, val accuracy: 0.420000\n",
      "Loss: 1.435129, Train accuracy: 0.558000, val accuracy: 0.400000\n",
      "Loss: 2.275589, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.237666, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.228922, Train accuracy: 0.184000, val accuracy: 0.190000\n",
      "Loss: 2.206098, Train accuracy: 0.210000, val accuracy: 0.200000\n",
      "Loss: 2.163669, Train accuracy: 0.282000, val accuracy: 0.290000\n",
      "Loss: 2.079329, Train accuracy: 0.315000, val accuracy: 0.280000\n",
      "Loss: 1.921463, Train accuracy: 0.374000, val accuracy: 0.310000\n",
      "Loss: 1.709434, Train accuracy: 0.486000, val accuracy: 0.320000\n",
      "Loss: 1.547797, Train accuracy: 0.481000, val accuracy: 0.340000\n",
      "Loss: 1.433302, Train accuracy: 0.557000, val accuracy: 0.460000\n",
      "Loss: 2.273152, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.235700, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.227535, Train accuracy: 0.175000, val accuracy: 0.210000\n",
      "Loss: 2.207935, Train accuracy: 0.214000, val accuracy: 0.210000\n",
      "Loss: 2.170664, Train accuracy: 0.272000, val accuracy: 0.270000\n",
      "Loss: 2.080208, Train accuracy: 0.284000, val accuracy: 0.260000\n",
      "Loss: 1.927186, Train accuracy: 0.407000, val accuracy: 0.330000\n",
      "Loss: 1.705240, Train accuracy: 0.462000, val accuracy: 0.390000\n",
      "Loss: 1.568639, Train accuracy: 0.470000, val accuracy: 0.360000\n",
      "Loss: 1.641039, Train accuracy: 0.458000, val accuracy: 0.320000\n",
      "Loss: 2.276638, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.239448, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.233157, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.224881, Train accuracy: 0.191000, val accuracy: 0.210000\n",
      "Loss: 2.210423, Train accuracy: 0.199000, val accuracy: 0.200000\n",
      "Loss: 2.198328, Train accuracy: 0.204000, val accuracy: 0.200000\n",
      "Loss: 2.185142, Train accuracy: 0.216000, val accuracy: 0.190000\n",
      "Loss: 2.176998, Train accuracy: 0.219000, val accuracy: 0.220000\n",
      "Loss: 2.169303, Train accuracy: 0.228000, val accuracy: 0.230000\n",
      "Loss: 2.163765, Train accuracy: 0.234000, val accuracy: 0.230000\n",
      "Loss: 2.269299, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.235126, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.232934, Train accuracy: 0.191000, val accuracy: 0.200000\n",
      "Loss: 2.219701, Train accuracy: 0.195000, val accuracy: 0.200000\n",
      "Loss: 2.204652, Train accuracy: 0.202000, val accuracy: 0.220000\n",
      "Loss: 2.189809, Train accuracy: 0.203000, val accuracy: 0.190000\n",
      "Loss: 2.180600, Train accuracy: 0.220000, val accuracy: 0.200000\n",
      "Loss: 2.168020, Train accuracy: 0.230000, val accuracy: 0.220000\n",
      "Loss: 2.163315, Train accuracy: 0.232000, val accuracy: 0.230000\n",
      "Loss: 2.155787, Train accuracy: 0.240000, val accuracy: 0.240000\n",
      "Loss: 2.275045, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.236367, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.230654, Train accuracy: 0.184000, val accuracy: 0.230000\n",
      "Loss: 2.220116, Train accuracy: 0.186000, val accuracy: 0.240000\n",
      "Loss: 2.211957, Train accuracy: 0.198000, val accuracy: 0.190000\n",
      "Loss: 2.196493, Train accuracy: 0.205000, val accuracy: 0.190000\n",
      "Loss: 2.185989, Train accuracy: 0.208000, val accuracy: 0.190000\n",
      "Loss: 2.176409, Train accuracy: 0.208000, val accuracy: 0.190000\n",
      "Loss: 2.171384, Train accuracy: 0.213000, val accuracy: 0.200000\n",
      "Loss: 2.166520, Train accuracy: 0.223000, val accuracy: 0.200000\n",
      "Loss: 2.276050, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.239640, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.234279, Train accuracy: 0.191000, val accuracy: 0.200000\n",
      "Loss: 2.224794, Train accuracy: 0.192000, val accuracy: 0.240000\n",
      "Loss: 2.198777, Train accuracy: 0.206000, val accuracy: 0.190000\n",
      "Loss: 2.174279, Train accuracy: 0.209000, val accuracy: 0.210000\n",
      "Loss: 2.149080, Train accuracy: 0.242000, val accuracy: 0.230000\n",
      "Loss: 2.119916, Train accuracy: 0.285000, val accuracy: 0.250000\n",
      "Loss: 2.085076, Train accuracy: 0.297000, val accuracy: 0.290000\n",
      "Loss: 2.049244, Train accuracy: 0.317000, val accuracy: 0.310000\n",
      "Loss: 2.276535, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.235364, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.234013, Train accuracy: 0.184000, val accuracy: 0.260000\n",
      "Loss: 2.218726, Train accuracy: 0.202000, val accuracy: 0.200000\n",
      "Loss: 2.200739, Train accuracy: 0.218000, val accuracy: 0.240000\n",
      "Loss: 2.169258, Train accuracy: 0.242000, val accuracy: 0.260000\n",
      "Loss: 2.145197, Train accuracy: 0.249000, val accuracy: 0.260000\n",
      "Loss: 2.106203, Train accuracy: 0.267000, val accuracy: 0.280000\n",
      "Loss: 2.067213, Train accuracy: 0.297000, val accuracy: 0.310000\n",
      "Loss: 2.035974, Train accuracy: 0.303000, val accuracy: 0.280000\n",
      "Loss: 2.275691, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.236387, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.238010, Train accuracy: 0.185000, val accuracy: 0.250000\n",
      "Loss: 2.214170, Train accuracy: 0.186000, val accuracy: 0.220000\n",
      "Loss: 2.198777, Train accuracy: 0.222000, val accuracy: 0.230000\n",
      "Loss: 2.173846, Train accuracy: 0.249000, val accuracy: 0.250000\n",
      "Loss: 2.147470, Train accuracy: 0.281000, val accuracy: 0.270000\n",
      "Loss: 2.102811, Train accuracy: 0.281000, val accuracy: 0.310000\n",
      "Loss: 2.070566, Train accuracy: 0.285000, val accuracy: 0.310000\n",
      "Loss: 2.041698, Train accuracy: 0.301000, val accuracy: 0.320000\n",
      "Loss: 2.274654, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.237590, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.231801, Train accuracy: 0.191000, val accuracy: 0.180000\n",
      "Loss: 2.211247, Train accuracy: 0.180000, val accuracy: 0.170000\n",
      "Loss: 2.177413, Train accuracy: 0.236000, val accuracy: 0.220000\n",
      "Loss: 2.119688, Train accuracy: 0.298000, val accuracy: 0.290000\n",
      "Loss: 2.002757, Train accuracy: 0.372000, val accuracy: 0.350000\n",
      "Loss: 1.881802, Train accuracy: 0.389000, val accuracy: 0.280000\n",
      "Loss: 1.754773, Train accuracy: 0.464000, val accuracy: 0.370000\n",
      "Loss: 1.606891, Train accuracy: 0.491000, val accuracy: 0.360000\n",
      "Loss: 2.275780, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.237960, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.229234, Train accuracy: 0.190000, val accuracy: 0.220000\n",
      "Loss: 2.205805, Train accuracy: 0.198000, val accuracy: 0.170000\n",
      "Loss: 2.176002, Train accuracy: 0.224000, val accuracy: 0.190000\n",
      "Loss: 2.135744, Train accuracy: 0.267000, val accuracy: 0.260000\n",
      "Loss: 2.072985, Train accuracy: 0.293000, val accuracy: 0.230000\n",
      "Loss: 1.975216, Train accuracy: 0.421000, val accuracy: 0.360000\n",
      "Loss: 1.799958, Train accuracy: 0.478000, val accuracy: 0.330000\n",
      "Loss: 1.654437, Train accuracy: 0.533000, val accuracy: 0.380000\n",
      "Loss: 2.278881, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.235766, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.232909, Train accuracy: 0.186000, val accuracy: 0.180000\n",
      "Loss: 2.213264, Train accuracy: 0.184000, val accuracy: 0.220000\n",
      "Loss: 2.174974, Train accuracy: 0.235000, val accuracy: 0.230000\n",
      "Loss: 2.125946, Train accuracy: 0.279000, val accuracy: 0.290000\n",
      "Loss: 2.035988, Train accuracy: 0.343000, val accuracy: 0.280000\n",
      "Loss: 1.897492, Train accuracy: 0.439000, val accuracy: 0.360000\n",
      "Loss: 1.771879, Train accuracy: 0.480000, val accuracy: 0.400000\n",
      "Loss: 1.666162, Train accuracy: 0.514000, val accuracy: 0.370000\n",
      "Loss: 2.276848, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.235388, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.232496, Train accuracy: 0.195000, val accuracy: 0.190000\n",
      "Loss: 2.209472, Train accuracy: 0.205000, val accuracy: 0.180000\n",
      "Loss: 2.174071, Train accuracy: 0.259000, val accuracy: 0.290000\n",
      "Loss: 2.113214, Train accuracy: 0.302000, val accuracy: 0.300000\n",
      "Loss: 2.006057, Train accuracy: 0.341000, val accuracy: 0.300000\n",
      "Loss: 1.889007, Train accuracy: 0.434000, val accuracy: 0.360000\n",
      "Loss: 1.678440, Train accuracy: 0.504000, val accuracy: 0.370000\n",
      "Loss: 1.621421, Train accuracy: 0.521000, val accuracy: 0.350000\n",
      "Loss: 2.275045, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.234299, Train accuracy: 0.184000, val accuracy: 0.220000\n",
      "Loss: 2.227000, Train accuracy: 0.191000, val accuracy: 0.190000\n",
      "Loss: 2.207558, Train accuracy: 0.199000, val accuracy: 0.190000\n",
      "Loss: 2.179065, Train accuracy: 0.241000, val accuracy: 0.240000\n",
      "Loss: 2.107735, Train accuracy: 0.283000, val accuracy: 0.270000\n",
      "Loss: 2.010187, Train accuracy: 0.368000, val accuracy: 0.330000\n",
      "Loss: 1.791304, Train accuracy: 0.438000, val accuracy: 0.340000\n",
      "Loss: 1.623339, Train accuracy: 0.511000, val accuracy: 0.410000\n",
      "Loss: 1.561968, Train accuracy: 0.533000, val accuracy: 0.340000\n",
      "Loss: 2.272690, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.233975, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.227906, Train accuracy: 0.199000, val accuracy: 0.200000\n",
      "Loss: 2.201114, Train accuracy: 0.228000, val accuracy: 0.240000\n",
      "Loss: 2.165222, Train accuracy: 0.251000, val accuracy: 0.280000\n",
      "Loss: 2.096066, Train accuracy: 0.320000, val accuracy: 0.330000\n",
      "Loss: 1.957943, Train accuracy: 0.369000, val accuracy: 0.290000\n",
      "Loss: 1.797831, Train accuracy: 0.463000, val accuracy: 0.370000\n",
      "Loss: 1.740746, Train accuracy: 0.474000, val accuracy: 0.340000\n",
      "Loss: 1.651581, Train accuracy: 0.560000, val accuracy: 0.440000\n",
      "Loss: 2.303714, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286031, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279314, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276004, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273471, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.272856, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.271248, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.269824, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.269570, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.268355, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303401, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285264, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277339, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.274954, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273384, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.272866, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.271219, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.271111, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.269029, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.268557, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.305924, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286672, Train accuracy: 0.185000, val accuracy: 0.160000\n",
      "Loss: 2.278363, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276373, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.275741, Train accuracy: 0.181000, val accuracy: 0.220000\n",
      "Loss: 2.272080, Train accuracy: 0.184000, val accuracy: 0.220000\n",
      "Loss: 2.269835, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.270573, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.269959, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.269363, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.301961, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288067, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279619, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278544, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276695, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276723, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273448, Train accuracy: 0.188000, val accuracy: 0.180000\n",
      "Loss: 2.273383, Train accuracy: 0.177000, val accuracy: 0.230000\n",
      "Loss: 2.270563, Train accuracy: 0.188000, val accuracy: 0.190000\n",
      "Loss: 2.270236, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301383, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286757, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.280026, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276699, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.275018, Train accuracy: 0.180000, val accuracy: 0.220000\n",
      "Loss: 2.271935, Train accuracy: 0.187000, val accuracy: 0.180000\n",
      "Loss: 2.271773, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273673, Train accuracy: 0.180000, val accuracy: 0.200000\n",
      "Loss: 2.269722, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.269282, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302794, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286186, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279207, Train accuracy: 0.185000, val accuracy: 0.180000\n",
      "Loss: 2.274668, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.274262, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.271838, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.274062, Train accuracy: 0.187000, val accuracy: 0.180000\n",
      "Loss: 2.272240, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.272556, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.271837, Train accuracy: 0.179000, val accuracy: 0.230000\n",
      "Loss: 2.306902, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286683, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278529, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284092, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279651, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281965, Train accuracy: 0.183000, val accuracy: 0.170000\n",
      "Loss: 2.282899, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277084, Train accuracy: 0.177000, val accuracy: 0.230000\n",
      "Loss: 2.281124, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284827, Train accuracy: 0.181000, val accuracy: 0.220000\n",
      "Loss: 2.306748, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285201, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.280073, Train accuracy: 0.182000, val accuracy: 0.220000\n",
      "Loss: 2.281701, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276981, Train accuracy: 0.184000, val accuracy: 0.200000\n",
      "Loss: 2.279664, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281294, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278389, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277837, Train accuracy: 0.183000, val accuracy: 0.220000\n",
      "Loss: 2.277979, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.305265, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284234, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277921, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.280688, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283457, Train accuracy: 0.180000, val accuracy: 0.200000\n",
      "Loss: 2.279103, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.280467, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278042, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.276059, Train accuracy: 0.180000, val accuracy: 0.180000\n",
      "Loss: 2.276927, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303039, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284443, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281429, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279490, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.280858, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283740, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283433, Train accuracy: 0.185000, val accuracy: 0.200000\n",
      "Loss: 2.279664, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283293, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279142, Train accuracy: 0.183000, val accuracy: 0.240000\n",
      "Loss: 2.308668, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284605, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279115, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279947, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281511, Train accuracy: 0.183000, val accuracy: 0.190000\n",
      "Loss: 2.282011, Train accuracy: 0.182000, val accuracy: 0.250000\n",
      "Loss: 2.286728, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278309, Train accuracy: 0.181000, val accuracy: 0.220000\n",
      "Loss: 2.282410, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289369, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.304709, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284106, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281093, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287533, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284722, Train accuracy: 0.179000, val accuracy: 0.210000\n",
      "Loss: 2.284859, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281860, Train accuracy: 0.186000, val accuracy: 0.190000\n",
      "Loss: 2.282718, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283553, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284208, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "best validation accuracy achieved: 0.480000\n",
      "Wall time: 18min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "# learning_rate = 1e-4\n",
    "# reg_strength = 1e-3\n",
    "# learning_rate_decay = 0.999\n",
    "# hidden_layer_size = 128\n",
    "# num_epochs = 20\n",
    "# batch_size = 64\n",
    "\n",
    "train_size = 1000\n",
    "val_size = 100\n",
    "train_X_, train_y_, val_X_, val_y_ = \\\n",
    "                                train_X[:train_size], train_y[:train_size], val_X[:val_size], val_y[:val_size]\n",
    "dataset = Dataset(train_X_, train_y_, val_X_, val_y_)\n",
    "\n",
    "learning_rates = np.logspace(-8, -1, num=5)\n",
    "reg_strengths = np.logspace(-8, -1, num=5)\n",
    "learning_rate_decays = [0.7, 0.8, 0.95, 0.99] \n",
    "hidden_layer_sizes = [128]\n",
    "num_epochs_list = [10]\n",
    "batch_sizes = [64]\n",
    "momentums = [0.1, 0.2, 0.3]\n",
    "\n",
    "params_list = [learning_rates, reg_strengths, learning_rate_decays, \n",
    "               hidden_layer_sizes, num_epochs_list, batch_sizes, momentums]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "\n",
    "best_val_accuracy = 0\n",
    "for params in product(*params_list):\n",
    "    learning_rate, reg_strength, learning_rate_decay, hidden_layer_size, num_epochs, batch_size, momentum = params\n",
    "\n",
    "    model = TwoLayerNet(n_input = train_X_.shape[1], n_output = 10, \n",
    "                        hidden_layer_size=hidden_layer_size, reg=reg_strength)\n",
    "    \n",
    "\n",
    "    trainer = Trainer(model, dataset, MomentumSGD(momentum=momentum), num_epochs, \n",
    "                      batch_size, learning_rate, learning_rate_decay)\n",
    "\n",
    "    loss_history, train_history, val_history = trainer.fit()\n",
    "    val_accuracy = val_history[-1]\n",
    "\n",
    "    if val_accuracy >= best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_classifier = model\n",
    "        best_history = [loss_history, train_history, val_history]\n",
    "        best_param = params\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48 \n",
      " <model.TwoLayerNet object at 0x000002A85592F518> \n",
      " (0.1, 1e-08, 0.99, 128, 10, 64, 0.2) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "        best_val_accuracy, \"\\n\", \n",
    "        best_classifier, \"\\n\", \n",
    "#         best_history, \"\\n\", \n",
    "        best_param, \"\\n\" \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history, train_history, val_history = best_history\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history, label=\"train\")\n",
    "plt.plot(val_history, label=\"validation\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.386000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем еще улучшить модель\n",
    "### Для этого обучим модель с лучшими параметрами, но на 100 эпохах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.276785, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.236714, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.223861, Train accuracy: 0.190000, val accuracy: 0.180000\n",
      "Loss: 2.201527, Train accuracy: 0.180000, val accuracy: 0.170000\n",
      "Loss: 2.162762, Train accuracy: 0.254000, val accuracy: 0.250000\n",
      "Loss: 2.079605, Train accuracy: 0.316000, val accuracy: 0.280000\n",
      "Loss: 1.974540, Train accuracy: 0.427000, val accuracy: 0.290000\n",
      "Loss: 1.709001, Train accuracy: 0.496000, val accuracy: 0.360000\n",
      "Loss: 1.529802, Train accuracy: 0.452000, val accuracy: 0.350000\n",
      "Loss: 1.483013, Train accuracy: 0.591000, val accuracy: 0.440000\n",
      "Loss: 1.419012, Train accuracy: 0.592000, val accuracy: 0.470000\n",
      "Loss: 1.389562, Train accuracy: 0.515000, val accuracy: 0.340000\n",
      "Loss: 1.498018, Train accuracy: 0.604000, val accuracy: 0.400000\n",
      "Loss: 1.330750, Train accuracy: 0.620000, val accuracy: 0.530000\n",
      "Loss: 1.275386, Train accuracy: 0.710000, val accuracy: 0.460000\n",
      "Loss: 0.973653, Train accuracy: 0.732000, val accuracy: 0.430000\n",
      "Loss: 0.815204, Train accuracy: 0.763000, val accuracy: 0.520000\n",
      "Loss: 0.921874, Train accuracy: 0.745000, val accuracy: 0.430000\n",
      "Loss: 0.876602, Train accuracy: 0.777000, val accuracy: 0.490000\n",
      "Loss: 0.742893, Train accuracy: 0.754000, val accuracy: 0.480000\n",
      "Loss: 0.728487, Train accuracy: 0.766000, val accuracy: 0.440000\n",
      "Loss: 0.700689, Train accuracy: 0.846000, val accuracy: 0.520000\n",
      "Loss: 0.520444, Train accuracy: 0.868000, val accuracy: 0.500000\n",
      "Loss: 0.517052, Train accuracy: 0.846000, val accuracy: 0.590000\n",
      "Loss: 0.558322, Train accuracy: 0.828000, val accuracy: 0.550000\n",
      "Loss: 0.664749, Train accuracy: 0.823000, val accuracy: 0.470000\n",
      "Loss: 0.728791, Train accuracy: 0.803000, val accuracy: 0.510000\n",
      "Loss: 0.498690, Train accuracy: 0.806000, val accuracy: 0.530000\n",
      "Loss: 0.537213, Train accuracy: 0.900000, val accuracy: 0.480000\n",
      "Loss: 0.449343, Train accuracy: 0.931000, val accuracy: 0.550000\n",
      "Loss: 0.427871, Train accuracy: 0.923000, val accuracy: 0.560000\n",
      "Loss: 0.323473, Train accuracy: 0.894000, val accuracy: 0.520000\n",
      "Loss: 0.295404, Train accuracy: 0.917000, val accuracy: 0.560000\n",
      "Loss: 0.224235, Train accuracy: 0.959000, val accuracy: 0.550000\n",
      "Loss: 0.215525, Train accuracy: 0.964000, val accuracy: 0.510000\n",
      "Loss: 0.282431, Train accuracy: 0.887000, val accuracy: 0.530000\n",
      "Loss: 0.259400, Train accuracy: 0.932000, val accuracy: 0.490000\n",
      "Loss: 0.263765, Train accuracy: 0.940000, val accuracy: 0.570000\n",
      "Loss: 0.180724, Train accuracy: 0.967000, val accuracy: 0.600000\n",
      "Loss: 0.140995, Train accuracy: 0.985000, val accuracy: 0.560000\n",
      "Loss: 0.094803, Train accuracy: 0.986000, val accuracy: 0.550000\n",
      "Loss: 0.081800, Train accuracy: 0.977000, val accuracy: 0.480000\n",
      "Loss: 0.070829, Train accuracy: 0.994000, val accuracy: 0.530000\n",
      "Loss: 0.053698, Train accuracy: 0.997000, val accuracy: 0.520000\n",
      "Loss: 0.050440, Train accuracy: 0.987000, val accuracy: 0.520000\n",
      "Loss: 0.039707, Train accuracy: 0.997000, val accuracy: 0.530000\n",
      "Loss: 0.031674, Train accuracy: 0.997000, val accuracy: 0.550000\n",
      "Loss: 0.024267, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.028258, Train accuracy: 0.999000, val accuracy: 0.540000\n",
      "Loss: 0.022827, Train accuracy: 0.999000, val accuracy: 0.560000\n",
      "Loss: 0.018400, Train accuracy: 1.000000, val accuracy: 0.580000\n",
      "Loss: 0.015192, Train accuracy: 1.000000, val accuracy: 0.570000\n",
      "Loss: 0.013455, Train accuracy: 1.000000, val accuracy: 0.580000\n",
      "Loss: 0.012818, Train accuracy: 1.000000, val accuracy: 0.580000\n",
      "Loss: 0.012209, Train accuracy: 1.000000, val accuracy: 0.560000\n",
      "Loss: 0.011641, Train accuracy: 1.000000, val accuracy: 0.570000\n",
      "Loss: 0.011046, Train accuracy: 1.000000, val accuracy: 0.570000\n",
      "Loss: 0.010621, Train accuracy: 1.000000, val accuracy: 0.570000\n",
      "Loss: 0.010331, Train accuracy: 1.000000, val accuracy: 0.570000\n",
      "Loss: 0.009875, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.009449, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.009191, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.008970, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.008972, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.008577, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.008312, Train accuracy: 1.000000, val accuracy: 0.560000\n",
      "Loss: 0.008061, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.007924, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.007725, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.007451, Train accuracy: 1.000000, val accuracy: 0.560000\n",
      "Loss: 0.007323, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.007174, Train accuracy: 1.000000, val accuracy: 0.560000\n",
      "Loss: 0.007022, Train accuracy: 1.000000, val accuracy: 0.560000\n",
      "Loss: 0.006946, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.006800, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.006674, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.006525, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.006442, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.006397, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.006195, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.006083, Train accuracy: 1.000000, val accuracy: 0.560000\n",
      "Loss: 0.006073, Train accuracy: 1.000000, val accuracy: 0.560000\n",
      "Loss: 0.005895, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.005825, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.005764, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.005681, Train accuracy: 1.000000, val accuracy: 0.560000\n",
      "Loss: 0.005627, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.005449, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.005358, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.005285, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.005200, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.005134, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.005093, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.005074, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.005029, Train accuracy: 1.000000, val accuracy: 0.550000\n",
      "Loss: 0.004928, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.004866, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.004805, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.004768, Train accuracy: 1.000000, val accuracy: 0.540000\n",
      "Loss: 0.004767, Train accuracy: 1.000000, val accuracy: 0.540000\n"
     ]
    }
   ],
   "source": [
    "learning_rate, reg_strength, learning_rate_decay, hidden_layer_size, num_epochs, batch_size, momentum = best_param\n",
    "\n",
    "best_model = TwoLayerNet(n_input = train_X_.shape[1], n_output = 10, \n",
    "                    hidden_layer_size=hidden_layer_size, reg=reg_strength)\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "trainer = Trainer(best_model, dataset, MomentumSGD(momentum=momentum), num_epochs, \n",
    "                  batch_size, learning_rate, learning_rate_decay)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "val_accuracy = val_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history, label=\"train\")\n",
    "plt.plot(val_history, label=\"validation\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим, как наша улучшеная модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.541000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## И еще улучшим модель!\n",
    "### Вспомним, что мы для ускорения поиска параметров использовали усеченную выборку (1000 семплов). Теперь сделаем обучение лучшей модели на 100 эпохах и на полной выборке 10 000 семплов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.139274, Train accuracy: 0.344222, val accuracy: 0.376000\n",
      "Loss: 1.701042, Train accuracy: 0.514444, val accuracy: 0.519000\n",
      "Loss: 1.454665, Train accuracy: 0.634556, val accuracy: 0.610000\n",
      "Loss: 1.294999, Train accuracy: 0.615556, val accuracy: 0.591000\n",
      "Loss: 1.287238, Train accuracy: 0.637222, val accuracy: 0.603000\n",
      "Loss: 1.153797, Train accuracy: 0.742111, val accuracy: 0.694000\n",
      "Loss: 1.021687, Train accuracy: 0.703333, val accuracy: 0.662000\n",
      "Loss: 0.974814, Train accuracy: 0.729000, val accuracy: 0.674000\n",
      "Loss: 0.990081, Train accuracy: 0.739111, val accuracy: 0.652000\n",
      "Loss: 0.935182, Train accuracy: 0.755333, val accuracy: 0.698000\n",
      "Loss: 0.906089, Train accuracy: 0.762222, val accuracy: 0.676000\n",
      "Loss: 0.922433, Train accuracy: 0.755111, val accuracy: 0.671000\n",
      "Loss: 0.879539, Train accuracy: 0.756333, val accuracy: 0.673000\n",
      "Loss: 0.768566, Train accuracy: 0.784889, val accuracy: 0.681000\n",
      "Loss: 0.822421, Train accuracy: 0.800111, val accuracy: 0.711000\n",
      "Loss: 0.711715, Train accuracy: 0.803778, val accuracy: 0.704000\n",
      "Loss: 0.744490, Train accuracy: 0.792000, val accuracy: 0.686000\n",
      "Loss: 0.714105, Train accuracy: 0.808778, val accuracy: 0.710000\n",
      "Loss: 0.649169, Train accuracy: 0.809889, val accuracy: 0.704000\n",
      "Loss: 0.622259, Train accuracy: 0.837889, val accuracy: 0.731000\n",
      "Loss: 0.652799, Train accuracy: 0.821333, val accuracy: 0.699000\n",
      "Loss: 0.682811, Train accuracy: 0.841333, val accuracy: 0.706000\n",
      "Loss: 0.582035, Train accuracy: 0.843889, val accuracy: 0.713000\n",
      "Loss: 0.579661, Train accuracy: 0.827333, val accuracy: 0.704000\n",
      "Loss: 0.586982, Train accuracy: 0.838667, val accuracy: 0.700000\n",
      "Loss: 0.528206, Train accuracy: 0.825111, val accuracy: 0.695000\n",
      "Loss: 0.566835, Train accuracy: 0.852778, val accuracy: 0.716000\n",
      "Loss: 0.542476, Train accuracy: 0.863889, val accuracy: 0.715000\n",
      "Loss: 0.483043, Train accuracy: 0.835667, val accuracy: 0.697000\n",
      "Loss: 0.481418, Train accuracy: 0.879556, val accuracy: 0.731000\n",
      "Loss: 0.438967, Train accuracy: 0.887000, val accuracy: 0.729000\n",
      "Loss: 0.372010, Train accuracy: 0.900444, val accuracy: 0.745000\n",
      "Loss: 0.395803, Train accuracy: 0.898333, val accuracy: 0.732000\n",
      "Loss: 0.429639, Train accuracy: 0.849222, val accuracy: 0.704000\n",
      "Loss: 0.411554, Train accuracy: 0.891444, val accuracy: 0.726000\n",
      "Loss: 0.350118, Train accuracy: 0.901444, val accuracy: 0.726000\n",
      "Loss: 0.355326, Train accuracy: 0.908333, val accuracy: 0.737000\n",
      "Loss: 0.282181, Train accuracy: 0.912889, val accuracy: 0.739000\n",
      "Loss: 0.317739, Train accuracy: 0.895667, val accuracy: 0.728000\n",
      "Loss: 0.352907, Train accuracy: 0.908889, val accuracy: 0.725000\n",
      "Loss: 0.362931, Train accuracy: 0.869000, val accuracy: 0.708000\n",
      "Loss: 0.353311, Train accuracy: 0.920222, val accuracy: 0.735000\n",
      "Loss: 0.285926, Train accuracy: 0.931444, val accuracy: 0.741000\n",
      "Loss: 0.299936, Train accuracy: 0.935778, val accuracy: 0.736000\n",
      "Loss: 0.223685, Train accuracy: 0.938333, val accuracy: 0.757000\n",
      "Loss: 0.220508, Train accuracy: 0.939444, val accuracy: 0.749000\n",
      "Loss: 0.243085, Train accuracy: 0.937444, val accuracy: 0.750000\n",
      "Loss: 0.227490, Train accuracy: 0.905000, val accuracy: 0.728000\n",
      "Loss: 0.250225, Train accuracy: 0.926111, val accuracy: 0.727000\n",
      "Loss: 0.221125, Train accuracy: 0.946333, val accuracy: 0.755000\n",
      "Loss: 0.200187, Train accuracy: 0.947111, val accuracy: 0.739000\n",
      "Loss: 0.170286, Train accuracy: 0.948778, val accuracy: 0.732000\n",
      "Loss: 0.202567, Train accuracy: 0.942444, val accuracy: 0.731000\n",
      "Loss: 0.240333, Train accuracy: 0.955111, val accuracy: 0.754000\n",
      "Loss: 0.160594, Train accuracy: 0.946778, val accuracy: 0.738000\n",
      "Loss: 0.177363, Train accuracy: 0.960889, val accuracy: 0.747000\n",
      "Loss: 0.145750, Train accuracy: 0.961444, val accuracy: 0.758000\n",
      "Loss: 0.159437, Train accuracy: 0.963556, val accuracy: 0.749000\n",
      "Loss: 0.141280, Train accuracy: 0.963222, val accuracy: 0.742000\n",
      "Loss: 0.116710, Train accuracy: 0.969444, val accuracy: 0.747000\n",
      "Loss: 0.129759, Train accuracy: 0.962222, val accuracy: 0.751000\n",
      "Loss: 0.120332, Train accuracy: 0.968222, val accuracy: 0.751000\n",
      "Loss: 0.114640, Train accuracy: 0.965000, val accuracy: 0.745000\n",
      "Loss: 0.107321, Train accuracy: 0.972111, val accuracy: 0.750000\n",
      "Loss: 0.102626, Train accuracy: 0.978556, val accuracy: 0.759000\n",
      "Loss: 0.083108, Train accuracy: 0.979778, val accuracy: 0.765000\n",
      "Loss: 0.102924, Train accuracy: 0.971333, val accuracy: 0.749000\n",
      "Loss: 0.090820, Train accuracy: 0.980222, val accuracy: 0.763000\n",
      "Loss: 0.103155, Train accuracy: 0.962556, val accuracy: 0.754000\n",
      "Loss: 0.115877, Train accuracy: 0.978667, val accuracy: 0.758000\n",
      "Loss: 0.092372, Train accuracy: 0.980333, val accuracy: 0.763000\n",
      "Loss: 0.073181, Train accuracy: 0.979889, val accuracy: 0.758000\n",
      "Loss: 0.070678, Train accuracy: 0.989889, val accuracy: 0.765000\n",
      "Loss: 0.067391, Train accuracy: 0.981333, val accuracy: 0.766000\n",
      "Loss: 0.065015, Train accuracy: 0.986000, val accuracy: 0.752000\n",
      "Loss: 0.052903, Train accuracy: 0.983222, val accuracy: 0.756000\n",
      "Loss: 0.061075, Train accuracy: 0.992778, val accuracy: 0.763000\n",
      "Loss: 0.042327, Train accuracy: 0.991778, val accuracy: 0.762000\n",
      "Loss: 0.041785, Train accuracy: 0.992333, val accuracy: 0.753000\n",
      "Loss: 0.038407, Train accuracy: 0.992556, val accuracy: 0.764000\n",
      "Loss: 0.027585, Train accuracy: 0.996111, val accuracy: 0.762000\n",
      "Loss: 0.026100, Train accuracy: 0.990333, val accuracy: 0.758000\n",
      "Loss: 0.043421, Train accuracy: 0.991333, val accuracy: 0.755000\n",
      "Loss: 0.030919, Train accuracy: 0.992000, val accuracy: 0.747000\n",
      "Loss: 0.045305, Train accuracy: 0.989889, val accuracy: 0.755000\n",
      "Loss: 0.040760, Train accuracy: 0.993222, val accuracy: 0.754000\n",
      "Loss: 0.045482, Train accuracy: 0.991333, val accuracy: 0.754000\n",
      "Loss: 0.025238, Train accuracy: 0.994667, val accuracy: 0.760000\n",
      "Loss: 0.019200, Train accuracy: 0.998222, val accuracy: 0.760000\n",
      "Loss: 0.016914, Train accuracy: 0.998111, val accuracy: 0.765000\n",
      "Loss: 0.016968, Train accuracy: 0.998222, val accuracy: 0.759000\n",
      "Loss: 0.014109, Train accuracy: 0.998889, val accuracy: 0.767000\n",
      "Loss: 0.013507, Train accuracy: 0.999000, val accuracy: 0.763000\n",
      "Loss: 0.012368, Train accuracy: 0.999111, val accuracy: 0.761000\n",
      "Loss: 0.011895, Train accuracy: 0.999333, val accuracy: 0.760000\n",
      "Loss: 0.010223, Train accuracy: 0.999222, val accuracy: 0.761000\n",
      "Loss: 0.009842, Train accuracy: 0.999333, val accuracy: 0.762000\n",
      "Loss: 0.009968, Train accuracy: 0.999000, val accuracy: 0.762000\n",
      "Loss: 0.010483, Train accuracy: 0.999444, val accuracy: 0.761000\n",
      "Loss: 0.009332, Train accuracy: 0.998222, val accuracy: 0.758000\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learning_rate, reg_strength, learning_rate_decay, hidden_layer_size, num_epochs, batch_size, momentum = best_param\n",
    "\n",
    "best_model = TwoLayerNet(n_input = train_X_.shape[1], n_output = 10, \n",
    "                    hidden_layer_size=hidden_layer_size, reg=reg_strength)\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(best_model, dataset, MomentumSGD(momentum=momentum), num_epochs, \n",
    "                  batch_size, learning_rate, learning_rate_decay)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "val_accuracy = val_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history, label=\"train\")\n",
    "plt.plot(val_history, label=\"validation\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим, как наша улучшеная модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.736000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I think good job!  :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
